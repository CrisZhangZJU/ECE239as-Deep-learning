{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import torchvision.transforms\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from Model.load_dataVAE import *\n",
    "from Model.VAE import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (2115, 22, 1000)\n",
      "Train labels shape:  (2115,)\n",
      "test data shape:  (443, 22, 1000)\n",
      "test labels shape:  (443,)\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, val_loader,_ = loader()(subject= \"ALL\",\n",
    "                                             batch_size= 30,\n",
    "                                             use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    criterion = nn.MSELoss(reduction='sum')\n",
    "    BCE = criterion(recon_x, x.view(-1, 22000))\n",
    "    #BCE = F.binary_cross_entropy(recon_x, x.view(-1, 22000), reduction='sum')\n",
    "\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD\n",
    "\n",
    "def train(epoch, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    latent = torch.tensor(np.array([]))\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 5 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "        latent = torch.cat((latent, model.Z_latent.double()), 0)\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "    return latent\n",
    "        \n",
    "\n",
    "def test(epoch, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    latent = torch.tensor(np.array([]))\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "            latent = torch.cat((latent, model.Z_latent.double()), 0)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> test set loss: {:.4f}'.format(test_loss))\n",
    "    return latent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_train(epoches = 10):\n",
    "    device = torch.device(\"cpu\")\n",
    "    latent_train = torch.tensor(np.array([]))\n",
    "    latent_test = torch.tensor(np.array([]))\n",
    "    for epoch in range(1, epoches+1):\n",
    "        latent_train = train(epoch,device)\n",
    "        latent_test = test(epoch,device)\n",
    "        if epoch == epoches:\n",
    "            latent_train = latent_train.view(-1, 20, 20)\n",
    "            latent_test = latent_test.view(-1, 20, 20)\n",
    "            return latent_train, latent_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (199, 22, 1000)\n",
      "Train labels shape:  (199,)\n",
      "test data shape:  (50, 22, 1000)\n",
      "test labels shape:  (50,)\n",
      "Validation data shape:  (38, 22, 1000)\n",
      "Validation labels shape:  (38,)\n",
      "Train Epoch: 1 [0/199 (0%)]\tLoss: 23953.806250\n",
      "Train Epoch: 1 [150/199 (71%)]\tLoss: 21814.770833\n",
      "====> Epoch: 1 Average loss: 22958.7546\n",
      "====> Validation set loss: 22568.9293\n",
      "Train Epoch: 2 [0/199 (0%)]\tLoss: 23619.870833\n",
      "Train Epoch: 2 [150/199 (71%)]\tLoss: 21021.764583\n",
      "====> Epoch: 2 Average loss: 22527.0256\n",
      "====> Validation set loss: 22191.4326\n",
      "Train Epoch: 3 [0/199 (0%)]\tLoss: 21197.347917\n",
      "Train Epoch: 3 [150/199 (71%)]\tLoss: 22539.258333\n",
      "====> Epoch: 3 Average loss: 21864.0397\n",
      "====> Validation set loss: 21654.8224\n",
      "Train Epoch: 4 [0/199 (0%)]\tLoss: 21482.404167\n",
      "Train Epoch: 4 [150/199 (71%)]\tLoss: 21107.900000\n",
      "====> Epoch: 4 Average loss: 20706.6465\n",
      "====> Validation set loss: 20757.3980\n",
      "Train Epoch: 5 [0/199 (0%)]\tLoss: 20847.033333\n",
      "Train Epoch: 5 [150/199 (71%)]\tLoss: 19291.158333\n",
      "====> Epoch: 5 Average loss: 19092.7367\n",
      "====> Validation set loss: 19666.7072\n",
      "Train Epoch: 6 [0/199 (0%)]\tLoss: 17717.543750\n",
      "Train Epoch: 6 [150/199 (71%)]\tLoss: 17883.052083\n",
      "====> Epoch: 6 Average loss: 17501.9077\n",
      "====> Validation set loss: 18733.5411\n",
      "Train Epoch: 7 [0/199 (0%)]\tLoss: 15963.555208\n",
      "Train Epoch: 7 [150/199 (71%)]\tLoss: 16280.359375\n",
      "====> Epoch: 7 Average loss: 16133.6300\n",
      "====> Validation set loss: 18054.5411\n",
      "Train Epoch: 8 [0/199 (0%)]\tLoss: 15106.969792\n",
      "Train Epoch: 8 [150/199 (71%)]\tLoss: 15971.662500\n",
      "====> Epoch: 8 Average loss: 15055.7019\n",
      "====> Validation set loss: 17504.5296\n",
      "Train Epoch: 9 [0/199 (0%)]\tLoss: 14630.868750\n",
      "Train Epoch: 9 [150/199 (71%)]\tLoss: 13222.256250\n",
      "====> Epoch: 9 Average loss: 14209.0862\n",
      "====> Validation set loss: 17131.7845\n",
      "Train Epoch: 10 [0/199 (0%)]\tLoss: 14269.117708\n",
      "Train Epoch: 10 [150/199 (71%)]\tLoss: 13585.863542\n",
      "====> Epoch: 10 Average loss: 13510.9231\n",
      "====> Validation set loss: 16771.2336\n",
      "Train Epoch: 11 [0/199 (0%)]\tLoss: 13424.566667\n",
      "Train Epoch: 11 [150/199 (71%)]\tLoss: 12670.035417\n",
      "====> Epoch: 11 Average loss: 12868.0437\n",
      "====> Validation set loss: 16464.0000\n",
      "Train Epoch: 12 [0/199 (0%)]\tLoss: 12946.047917\n",
      "Train Epoch: 12 [150/199 (71%)]\tLoss: 12893.311458\n",
      "====> Epoch: 12 Average loss: 12292.4152\n",
      "====> Validation set loss: 16236.4868\n",
      "Train Epoch: 13 [0/199 (0%)]\tLoss: 11655.641667\n",
      "Train Epoch: 13 [150/199 (71%)]\tLoss: 12214.555208\n",
      "====> Epoch: 13 Average loss: 11777.1039\n",
      "====> Validation set loss: 16082.5674\n",
      "Train Epoch: 14 [0/199 (0%)]\tLoss: 11082.110417\n",
      "Train Epoch: 14 [150/199 (71%)]\tLoss: 11381.991667\n",
      "====> Epoch: 14 Average loss: 11329.5661\n",
      "====> Validation set loss: 15879.8717\n",
      "Train Epoch: 15 [0/199 (0%)]\tLoss: 11334.539583\n",
      "Train Epoch: 15 [150/199 (71%)]\tLoss: 10800.084375\n",
      "====> Epoch: 15 Average loss: 10925.1388\n",
      "====> Validation set loss: 15787.1711\n",
      "Train Epoch: 16 [0/199 (0%)]\tLoss: 10583.707292\n",
      "Train Epoch: 16 [150/199 (71%)]\tLoss: 10577.168750\n",
      "====> Epoch: 16 Average loss: 10561.9842\n",
      "====> Validation set loss: 15631.8964\n",
      "Train Epoch: 17 [0/199 (0%)]\tLoss: 9760.763542\n",
      "Train Epoch: 17 [150/199 (71%)]\tLoss: 10361.602083\n",
      "====> Epoch: 17 Average loss: 10217.6391\n",
      "====> Validation set loss: 15539.8553\n",
      "Train Epoch: 18 [0/199 (0%)]\tLoss: 9106.905208\n",
      "Train Epoch: 18 [150/199 (71%)]\tLoss: 10235.778125\n",
      "====> Epoch: 18 Average loss: 9886.2163\n",
      "====> Validation set loss: 15413.9457\n",
      "Train Epoch: 19 [0/199 (0%)]\tLoss: 9183.602083\n",
      "Train Epoch: 19 [150/199 (71%)]\tLoss: 9119.707292\n",
      "====> Epoch: 19 Average loss: 9569.4647\n",
      "====> Validation set loss: 15331.3783\n",
      "Train Epoch: 20 [0/199 (0%)]\tLoss: 10166.440625\n",
      "Train Epoch: 20 [150/199 (71%)]\tLoss: 9763.868750\n",
      "====> Epoch: 20 Average loss: 9281.7403\n",
      "====> Validation set loss: 15232.4868\n",
      "Train Epoch: 21 [0/199 (0%)]\tLoss: 9588.023958\n",
      "Train Epoch: 21 [150/199 (71%)]\tLoss: 8908.000000\n",
      "====> Epoch: 21 Average loss: 9017.1479\n",
      "====> Validation set loss: 15173.0740\n",
      "Train Epoch: 22 [0/199 (0%)]\tLoss: 8323.623958\n",
      "Train Epoch: 22 [150/199 (71%)]\tLoss: 8433.231250\n",
      "====> Epoch: 22 Average loss: 8801.9150\n",
      "====> Validation set loss: 15119.1118\n",
      "Train Epoch: 23 [0/199 (0%)]\tLoss: 8819.465625\n",
      "Train Epoch: 23 [150/199 (71%)]\tLoss: 8613.917708\n",
      "====> Epoch: 23 Average loss: 8594.3714\n",
      "====> Validation set loss: 15066.8651\n",
      "Train Epoch: 24 [0/199 (0%)]\tLoss: 7736.730208\n",
      "Train Epoch: 24 [150/199 (71%)]\tLoss: 8492.443229\n",
      "====> Epoch: 24 Average loss: 8389.8526\n",
      "====> Validation set loss: 15009.1809\n",
      "Train Epoch: 25 [0/199 (0%)]\tLoss: 7698.030208\n",
      "Train Epoch: 25 [150/199 (71%)]\tLoss: 8732.881250\n",
      "====> Epoch: 25 Average loss: 8207.4725\n",
      "====> Validation set loss: 14968.9539\n",
      "Train Epoch: 26 [0/199 (0%)]\tLoss: 8409.703125\n",
      "Train Epoch: 26 [150/199 (71%)]\tLoss: 7872.839063\n",
      "====> Epoch: 26 Average loss: 8035.7175\n",
      "====> Validation set loss: 14886.9770\n",
      "Train Epoch: 27 [0/199 (0%)]\tLoss: 7827.660417\n",
      "Train Epoch: 27 [150/199 (71%)]\tLoss: 7568.982292\n",
      "====> Epoch: 27 Average loss: 7876.2339\n",
      "====> Validation set loss: 14847.1464\n",
      "Train Epoch: 28 [0/199 (0%)]\tLoss: 7206.478125\n",
      "Train Epoch: 28 [150/199 (71%)]\tLoss: 8301.376042\n",
      "====> Epoch: 28 Average loss: 7726.5196\n",
      "====> Validation set loss: 14878.0181\n",
      "Train Epoch: 29 [0/199 (0%)]\tLoss: 7951.857813\n",
      "Train Epoch: 29 [150/199 (71%)]\tLoss: 8230.475000\n",
      "====> Epoch: 29 Average loss: 7584.7052\n",
      "====> Validation set loss: 14842.4013\n",
      "Train Epoch: 30 [0/199 (0%)]\tLoss: 7087.229167\n",
      "Train Epoch: 30 [150/199 (71%)]\tLoss: 7829.308333\n",
      "====> Epoch: 30 Average loss: 7449.2953\n",
      "====> Validation set loss: 14744.4852\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "train_loader, test_loader, val_loader,_ = loader()(subject= 1,\n",
    "                                             batch_size= 30,\n",
    "                                             num_validation =38,use_cuda=False)\n",
    "model = VAE().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9,0.999), eps=1e-08, weight_decay=0.005)\n",
    "main_train(epoches = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (2115, 22, 1000)\n",
      "Train labels shape:  (2115,)\n",
      "test data shape:  (443, 22, 1000)\n",
      "test labels shape:  (443,)\n",
      "Train Epoch: 1 [0/2115 (0%)]\tLoss: 21838.325000\n",
      "Train Epoch: 1 [150/2115 (7%)]\tLoss: 23985.291667\n",
      "Train Epoch: 1 [300/2115 (14%)]\tLoss: 20394.975000\n",
      "Train Epoch: 1 [450/2115 (21%)]\tLoss: 21924.116667\n",
      "Train Epoch: 1 [600/2115 (28%)]\tLoss: 23390.458333\n",
      "Train Epoch: 1 [750/2115 (35%)]\tLoss: 27807.572917\n",
      "Train Epoch: 1 [900/2115 (42%)]\tLoss: 20482.443750\n",
      "Train Epoch: 1 [1050/2115 (49%)]\tLoss: 25567.877083\n",
      "Train Epoch: 1 [1200/2115 (56%)]\tLoss: 25019.402083\n",
      "Train Epoch: 1 [1350/2115 (63%)]\tLoss: 20330.031250\n",
      "Train Epoch: 1 [1500/2115 (70%)]\tLoss: 24301.308333\n",
      "Train Epoch: 1 [1650/2115 (77%)]\tLoss: 21245.945833\n",
      "Train Epoch: 1 [1800/2115 (85%)]\tLoss: 22731.902083\n",
      "Train Epoch: 1 [1950/2115 (92%)]\tLoss: 21285.312500\n",
      "Train Epoch: 1 [1050/2115 (99%)]\tLoss: 23323.608333\n",
      "====> Epoch: 1 Average loss: 21634.8221\n",
      "====> test set loss: 19563.9090\n",
      "Train Epoch: 2 [0/2115 (0%)]\tLoss: 17952.710417\n",
      "Train Epoch: 2 [150/2115 (7%)]\tLoss: 16472.186458\n",
      "Train Epoch: 2 [300/2115 (14%)]\tLoss: 16692.838542\n",
      "Train Epoch: 2 [450/2115 (21%)]\tLoss: 20344.952083\n",
      "Train Epoch: 2 [600/2115 (28%)]\tLoss: 18005.770833\n",
      "Train Epoch: 2 [750/2115 (35%)]\tLoss: 17936.747917\n",
      "Train Epoch: 2 [900/2115 (42%)]\tLoss: 18060.870833\n",
      "Train Epoch: 2 [1050/2115 (49%)]\tLoss: 16304.135417\n",
      "Train Epoch: 2 [1200/2115 (56%)]\tLoss: 16587.141667\n",
      "Train Epoch: 2 [1350/2115 (63%)]\tLoss: 16100.200000\n",
      "Train Epoch: 2 [1500/2115 (70%)]\tLoss: 14747.255208\n",
      "Train Epoch: 2 [1650/2115 (77%)]\tLoss: 17498.431250\n",
      "Train Epoch: 2 [1800/2115 (85%)]\tLoss: 14498.663542\n",
      "Train Epoch: 2 [1950/2115 (92%)]\tLoss: 14720.970833\n",
      "Train Epoch: 2 [1050/2115 (99%)]\tLoss: 15136.443750\n",
      "====> Epoch: 2 Average loss: 17482.3095\n",
      "====> test set loss: 16673.7607\n",
      "Train Epoch: 3 [0/2115 (0%)]\tLoss: 16312.748958\n",
      "Train Epoch: 3 [150/2115 (7%)]\tLoss: 17220.910417\n",
      "Train Epoch: 3 [300/2115 (14%)]\tLoss: 17889.027083\n",
      "Train Epoch: 3 [450/2115 (21%)]\tLoss: 17773.460417\n",
      "Train Epoch: 3 [600/2115 (28%)]\tLoss: 13960.739583\n",
      "Train Epoch: 3 [750/2115 (35%)]\tLoss: 15042.623958\n",
      "Train Epoch: 3 [900/2115 (42%)]\tLoss: 14757.829167\n",
      "Train Epoch: 3 [1050/2115 (49%)]\tLoss: 12381.056250\n",
      "Train Epoch: 3 [1200/2115 (56%)]\tLoss: 12471.256250\n",
      "Train Epoch: 3 [1350/2115 (63%)]\tLoss: 18671.879167\n",
      "Train Epoch: 3 [1500/2115 (70%)]\tLoss: 14189.103125\n",
      "Train Epoch: 3 [1650/2115 (77%)]\tLoss: 15038.716667\n",
      "Train Epoch: 3 [1800/2115 (85%)]\tLoss: 17256.504167\n",
      "Train Epoch: 3 [1950/2115 (92%)]\tLoss: 16270.923958\n",
      "Train Epoch: 3 [1050/2115 (99%)]\tLoss: 9619.535417\n",
      "====> Epoch: 3 Average loss: 15090.6335\n",
      "====> test set loss: 15247.8416\n",
      "Train Epoch: 4 [0/2115 (0%)]\tLoss: 15146.904167\n",
      "Train Epoch: 4 [150/2115 (7%)]\tLoss: 13471.739583\n",
      "Train Epoch: 4 [300/2115 (14%)]\tLoss: 13420.230208\n",
      "Train Epoch: 4 [450/2115 (21%)]\tLoss: 12859.018750\n",
      "Train Epoch: 4 [600/2115 (28%)]\tLoss: 15463.314583\n",
      "Train Epoch: 4 [750/2115 (35%)]\tLoss: 14272.240625\n",
      "Train Epoch: 4 [900/2115 (42%)]\tLoss: 12942.688542\n",
      "Train Epoch: 4 [1050/2115 (49%)]\tLoss: 12828.626042\n",
      "Train Epoch: 4 [1200/2115 (56%)]\tLoss: 12414.397917\n",
      "Train Epoch: 4 [1350/2115 (63%)]\tLoss: 11918.137500\n",
      "Train Epoch: 4 [1500/2115 (70%)]\tLoss: 12750.435417\n",
      "Train Epoch: 4 [1650/2115 (77%)]\tLoss: 15425.321875\n",
      "Train Epoch: 4 [1800/2115 (85%)]\tLoss: 13601.504167\n",
      "Train Epoch: 4 [1950/2115 (92%)]\tLoss: 12560.981250\n",
      "Train Epoch: 4 [1050/2115 (99%)]\tLoss: 13707.178125\n",
      "====> Epoch: 4 Average loss: 13709.0745\n",
      "====> test set loss: 14415.7751\n",
      "Train Epoch: 5 [0/2115 (0%)]\tLoss: 12838.603125\n",
      "Train Epoch: 5 [150/2115 (7%)]\tLoss: 14449.736458\n",
      "Train Epoch: 5 [300/2115 (14%)]\tLoss: 11974.807292\n",
      "Train Epoch: 5 [450/2115 (21%)]\tLoss: 12667.360417\n",
      "Train Epoch: 5 [600/2115 (28%)]\tLoss: 13846.951042\n",
      "Train Epoch: 5 [750/2115 (35%)]\tLoss: 13127.834375\n",
      "Train Epoch: 5 [900/2115 (42%)]\tLoss: 12952.920833\n",
      "Train Epoch: 5 [1050/2115 (49%)]\tLoss: 11664.831250\n",
      "Train Epoch: 5 [1200/2115 (56%)]\tLoss: 12719.282292\n",
      "Train Epoch: 5 [1350/2115 (63%)]\tLoss: 13875.529167\n",
      "Train Epoch: 5 [1500/2115 (70%)]\tLoss: 13165.922917\n",
      "Train Epoch: 5 [1650/2115 (77%)]\tLoss: 11359.357292\n",
      "Train Epoch: 5 [1800/2115 (85%)]\tLoss: 13229.992708\n",
      "Train Epoch: 5 [1950/2115 (92%)]\tLoss: 12599.070833\n",
      "Train Epoch: 5 [1050/2115 (99%)]\tLoss: 15328.010417\n",
      "====> Epoch: 5 Average loss: 12812.6826\n",
      "====> test set loss: 13865.4966\n",
      "Train Epoch: 6 [0/2115 (0%)]\tLoss: 12497.723958\n",
      "Train Epoch: 6 [150/2115 (7%)]\tLoss: 11806.251042\n",
      "Train Epoch: 6 [300/2115 (14%)]\tLoss: 13239.286458\n",
      "Train Epoch: 6 [450/2115 (21%)]\tLoss: 13114.446875\n",
      "Train Epoch: 6 [600/2115 (28%)]\tLoss: 13167.443750\n",
      "Train Epoch: 6 [750/2115 (35%)]\tLoss: 12673.668750\n",
      "Train Epoch: 6 [900/2115 (42%)]\tLoss: 13592.889583\n",
      "Train Epoch: 6 [1050/2115 (49%)]\tLoss: 11019.951042\n",
      "Train Epoch: 6 [1200/2115 (56%)]\tLoss: 12187.554167\n",
      "Train Epoch: 6 [1350/2115 (63%)]\tLoss: 12455.684375\n",
      "Train Epoch: 6 [1500/2115 (70%)]\tLoss: 10170.806250\n",
      "Train Epoch: 6 [1650/2115 (77%)]\tLoss: 9228.101042\n",
      "Train Epoch: 6 [1800/2115 (85%)]\tLoss: 10975.645833\n",
      "Train Epoch: 6 [1950/2115 (92%)]\tLoss: 10773.015625\n",
      "Train Epoch: 6 [1050/2115 (99%)]\tLoss: 10084.267708\n",
      "====> Epoch: 6 Average loss: 12242.4411\n",
      "====> test set loss: 13519.9594\n",
      "Train Epoch: 7 [0/2115 (0%)]\tLoss: 13619.296875\n",
      "Train Epoch: 7 [150/2115 (7%)]\tLoss: 12329.867708\n",
      "Train Epoch: 7 [300/2115 (14%)]\tLoss: 10907.027083\n",
      "Train Epoch: 7 [450/2115 (21%)]\tLoss: 13044.507292\n",
      "Train Epoch: 7 [600/2115 (28%)]\tLoss: 12013.605208\n",
      "Train Epoch: 7 [750/2115 (35%)]\tLoss: 9916.782292\n",
      "Train Epoch: 7 [900/2115 (42%)]\tLoss: 11886.976042\n",
      "Train Epoch: 7 [1050/2115 (49%)]\tLoss: 9920.417708\n",
      "Train Epoch: 7 [1200/2115 (56%)]\tLoss: 11065.958333\n",
      "Train Epoch: 7 [1350/2115 (63%)]\tLoss: 10859.031250\n",
      "Train Epoch: 7 [1500/2115 (70%)]\tLoss: 12217.010417\n",
      "Train Epoch: 7 [1650/2115 (77%)]\tLoss: 12663.542708\n",
      "Train Epoch: 7 [1800/2115 (85%)]\tLoss: 11486.027083\n",
      "Train Epoch: 7 [1950/2115 (92%)]\tLoss: 12950.964583\n",
      "Train Epoch: 7 [1050/2115 (99%)]\tLoss: 12163.403125\n",
      "====> Epoch: 7 Average loss: 11814.3404\n",
      "====> test set loss: 13319.2441\n",
      "Train Epoch: 8 [0/2115 (0%)]\tLoss: 12083.853125\n",
      "Train Epoch: 8 [150/2115 (7%)]\tLoss: 10412.431250\n",
      "Train Epoch: 8 [300/2115 (14%)]\tLoss: 11836.109375\n",
      "Train Epoch: 8 [450/2115 (21%)]\tLoss: 9883.382292\n",
      "Train Epoch: 8 [600/2115 (28%)]\tLoss: 10953.588542\n",
      "Train Epoch: 8 [750/2115 (35%)]\tLoss: 12072.906250\n",
      "Train Epoch: 8 [900/2115 (42%)]\tLoss: 13286.478125\n",
      "Train Epoch: 8 [1050/2115 (49%)]\tLoss: 13020.613542\n",
      "Train Epoch: 8 [1200/2115 (56%)]\tLoss: 11369.579167\n",
      "Train Epoch: 8 [1350/2115 (63%)]\tLoss: 11086.807292\n",
      "Train Epoch: 8 [1500/2115 (70%)]\tLoss: 10485.452083\n",
      "Train Epoch: 8 [1650/2115 (77%)]\tLoss: 13060.948958\n",
      "Train Epoch: 8 [1800/2115 (85%)]\tLoss: 12187.672917\n",
      "Train Epoch: 8 [1950/2115 (92%)]\tLoss: 12084.244792\n",
      "Train Epoch: 8 [1050/2115 (99%)]\tLoss: 12391.958333\n",
      "====> Epoch: 8 Average loss: 11478.9096\n",
      "====> test set loss: 13108.8221\n",
      "Train Epoch: 9 [0/2115 (0%)]\tLoss: 10712.775000\n",
      "Train Epoch: 9 [150/2115 (7%)]\tLoss: 11927.780208\n",
      "Train Epoch: 9 [300/2115 (14%)]\tLoss: 11883.756250\n",
      "Train Epoch: 9 [450/2115 (21%)]\tLoss: 11535.987500\n",
      "Train Epoch: 9 [600/2115 (28%)]\tLoss: 11614.832292\n",
      "Train Epoch: 9 [750/2115 (35%)]\tLoss: 10711.789583\n",
      "Train Epoch: 9 [900/2115 (42%)]\tLoss: 11329.264583\n",
      "Train Epoch: 9 [1050/2115 (49%)]\tLoss: 11394.219792\n",
      "Train Epoch: 9 [1200/2115 (56%)]\tLoss: 11087.467708\n",
      "Train Epoch: 9 [1350/2115 (63%)]\tLoss: 11001.716667\n",
      "Train Epoch: 9 [1500/2115 (70%)]\tLoss: 10795.954167\n",
      "Train Epoch: 9 [1650/2115 (77%)]\tLoss: 12301.116667\n",
      "Train Epoch: 9 [1800/2115 (85%)]\tLoss: 9943.411458\n",
      "Train Epoch: 9 [1950/2115 (92%)]\tLoss: 10628.778125\n",
      "Train Epoch: 9 [1050/2115 (99%)]\tLoss: 9048.444792\n",
      "====> Epoch: 9 Average loss: 11177.6087\n",
      "====> test set loss: 12927.9064\n",
      "Train Epoch: 10 [0/2115 (0%)]\tLoss: 9552.507292\n",
      "Train Epoch: 10 [150/2115 (7%)]\tLoss: 10669.839583\n",
      "Train Epoch: 10 [300/2115 (14%)]\tLoss: 11262.083333\n",
      "Train Epoch: 10 [450/2115 (21%)]\tLoss: 10414.367708\n",
      "Train Epoch: 10 [600/2115 (28%)]\tLoss: 10366.108333\n",
      "Train Epoch: 10 [750/2115 (35%)]\tLoss: 10789.742708\n",
      "Train Epoch: 10 [900/2115 (42%)]\tLoss: 11544.181250\n",
      "Train Epoch: 10 [1050/2115 (49%)]\tLoss: 11796.543750\n",
      "Train Epoch: 10 [1200/2115 (56%)]\tLoss: 9397.041667\n",
      "Train Epoch: 10 [1350/2115 (63%)]\tLoss: 12473.112500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [1500/2115 (70%)]\tLoss: 11572.504167\n",
      "Train Epoch: 10 [1650/2115 (77%)]\tLoss: 10959.182292\n",
      "Train Epoch: 10 [1800/2115 (85%)]\tLoss: 9779.097917\n",
      "Train Epoch: 10 [1950/2115 (92%)]\tLoss: 11753.352083\n",
      "Train Epoch: 10 [1050/2115 (99%)]\tLoss: 11740.563542\n",
      "====> Epoch: 10 Average loss: 10906.7079\n",
      "====> test set loss: 12771.2312\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "train_loader, test_loader, val_loader,_ = loader()(subject= \"ALL\",\n",
    "                                             batch_size= 30,\n",
    "                                             use_cuda=False)\n",
    "model = VAE().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9,0.999), eps=1e-08, weight_decay=0.005)\n",
    "latent_train, latent_test = main_train(epoches = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2115, 20, 20])\n",
      "torch.Size([443, 20, 20])\n",
      "(2115, 20, 20)\n",
      "(443, 20, 20)\n"
     ]
    }
   ],
   "source": [
    "print(latent_train.size())\n",
    "print(latent_test.size())\n",
    "np.save(\"latent_train.npy\",latent_train.data.numpy())\n",
    "np.save(\"latent_test.npy\",latent_test.data.numpy())\n",
    "c = np.load( \"latent_train.npy\" )\n",
    "d = np.load( \"latent_test.npy\" )\n",
    "print(c.shape)\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model.load_dataVAE_CNN import *\n",
    "from Model.VAE_ShallowCNN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (200, 20, 20)\n",
      "Train labels shape:  (200,)\n",
      "test data shape:  (50, 20, 20)\n",
      "test labels shape:  (50,)\n",
      "Validation data shape:  (37, 20, 20)\n",
      "Validation labels shape:  (37,)\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, val_loader, _ = loader()(subject = 1,\n",
    "                                             batch_size= 30,\n",
    "                                             num_validation =37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = F.cross_entropy\n",
    "\n",
    "def train1(epoch,device):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device).long()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criteria(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 5 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test1(test_loader=test_loader, mode = 'val',device=None):\n",
    "    # train mode to get the train accuracy \n",
    "    # val mode to get the validation accuracy\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device).long()\n",
    "            output = model(data)\n",
    "            test_loss += criteria(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    if mode == 'train':\n",
    "        print('train loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "            test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "        \n",
    "\n",
    "    else:\n",
    "        print('validation loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    return [test_loss,correct / len(test_loader.dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_train(epoches = 8):\n",
    "    stats = {}\n",
    "    stats['train'] = []\n",
    "    stats['val']  = []\n",
    "    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    epoches = range(epoches)\n",
    "    for epoch in epoches:\n",
    "        train1(epoch,device)\n",
    "        stats['train'].append(test1(train_loader, mode='train',device=device))\n",
    "        stats['val'].append(test1(val_loader, mode='val',device=device))\n",
    "\n",
    "    print('Test set result:')\n",
    "    test1(test_loader, mode = 'val',device=device)\n",
    "\n",
    "    stats['val']  = np.array(stats['val'])\n",
    "    stats['train'] = np.array(stats['train'])\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2,figsize = (8,4))\n",
    "    ax[0].plot(epoches,stats['val'][:,0],epoches,stats['train'][:,0])\n",
    "\n",
    "    ax[0].legend(['validation','train'])\n",
    "    ax[0].set_title('loss')\n",
    "\n",
    "    ax[1].plot(epoches,stats['val'][:,1],epoches,stats['train'][:,1])\n",
    "\n",
    "    ax[1].legend(['validation','train'])\n",
    "    ax[1].set_title('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (1773, 20, 20)\n",
      "Train labels shape:  (1773,)\n",
      "test data shape:  (443, 20, 20)\n",
      "test labels shape:  (443,)\n",
      "Validation data shape:  (342, 20, 20)\n",
      "Validation labels shape:  (342,)\n",
      "Train Epoch: 0 [0/1773 (0%)]\tLoss: 1.374406\n",
      "Train Epoch: 0 [150/1773 (8%)]\tLoss: 1.375352\n",
      "Train Epoch: 0 [300/1773 (17%)]\tLoss: 1.388853\n",
      "Train Epoch: 0 [450/1773 (25%)]\tLoss: 1.370582\n",
      "Train Epoch: 0 [600/1773 (33%)]\tLoss: 1.409234\n",
      "Train Epoch: 0 [750/1773 (42%)]\tLoss: 1.363615\n",
      "Train Epoch: 0 [900/1773 (50%)]\tLoss: 1.393233\n",
      "Train Epoch: 0 [1050/1773 (58%)]\tLoss: 1.353279\n",
      "Train Epoch: 0 [1200/1773 (67%)]\tLoss: 1.379815\n",
      "Train Epoch: 0 [1350/1773 (75%)]\tLoss: 1.361860\n",
      "Train Epoch: 0 [1500/1773 (83%)]\tLoss: 1.390643\n",
      "Train Epoch: 0 [1650/1773 (92%)]\tLoss: 1.439255\n",
      "train loss: 1.3791, Accuracy: 533/1773 (30%)\n",
      "validation loss: 1.3864, Accuracy: 86/342 (25%)\n",
      "\n",
      "Train Epoch: 1 [0/1773 (0%)]\tLoss: 1.362750\n",
      "Train Epoch: 1 [150/1773 (8%)]\tLoss: 1.406488\n",
      "Train Epoch: 1 [300/1773 (17%)]\tLoss: 1.360149\n",
      "Train Epoch: 1 [450/1773 (25%)]\tLoss: 1.354157\n",
      "Train Epoch: 1 [600/1773 (33%)]\tLoss: 1.369728\n",
      "Train Epoch: 1 [750/1773 (42%)]\tLoss: 1.373466\n",
      "Train Epoch: 1 [900/1773 (50%)]\tLoss: 1.381423\n",
      "Train Epoch: 1 [1050/1773 (58%)]\tLoss: 1.339666\n",
      "Train Epoch: 1 [1200/1773 (67%)]\tLoss: 1.401561\n",
      "Train Epoch: 1 [1350/1773 (75%)]\tLoss: 1.362564\n",
      "Train Epoch: 1 [1500/1773 (83%)]\tLoss: 1.377796\n",
      "Train Epoch: 1 [1650/1773 (92%)]\tLoss: 1.373536\n",
      "train loss: 1.3651, Accuracy: 974/1773 (55%)\n",
      "validation loss: 1.3859, Accuracy: 90/342 (26%)\n",
      "\n",
      "Train Epoch: 2 [0/1773 (0%)]\tLoss: 1.371695\n",
      "Train Epoch: 2 [150/1773 (8%)]\tLoss: 1.369638\n",
      "Train Epoch: 2 [300/1773 (17%)]\tLoss: 1.361804\n",
      "Train Epoch: 2 [450/1773 (25%)]\tLoss: 1.373600\n",
      "Train Epoch: 2 [600/1773 (33%)]\tLoss: 1.386074\n",
      "Train Epoch: 2 [750/1773 (42%)]\tLoss: 1.372748\n",
      "Train Epoch: 2 [900/1773 (50%)]\tLoss: 1.370839\n",
      "Train Epoch: 2 [1050/1773 (58%)]\tLoss: 1.362749\n",
      "Train Epoch: 2 [1200/1773 (67%)]\tLoss: 1.351299\n",
      "Train Epoch: 2 [1350/1773 (75%)]\tLoss: 1.348472\n",
      "Train Epoch: 2 [1500/1773 (83%)]\tLoss: 1.378489\n",
      "Train Epoch: 2 [1650/1773 (92%)]\tLoss: 1.355197\n",
      "train loss: 1.3576, Accuracy: 787/1773 (44%)\n",
      "validation loss: 1.3855, Accuracy: 92/342 (27%)\n",
      "\n",
      "Train Epoch: 3 [0/1773 (0%)]\tLoss: 1.362531\n",
      "Train Epoch: 3 [150/1773 (8%)]\tLoss: 1.378657\n",
      "Train Epoch: 3 [300/1773 (17%)]\tLoss: 1.384363\n",
      "Train Epoch: 3 [450/1773 (25%)]\tLoss: 1.361916\n",
      "Train Epoch: 3 [600/1773 (33%)]\tLoss: 1.371964\n",
      "Train Epoch: 3 [750/1773 (42%)]\tLoss: 1.348586\n",
      "Train Epoch: 3 [900/1773 (50%)]\tLoss: 1.339671\n",
      "Train Epoch: 3 [1050/1773 (58%)]\tLoss: 1.358323\n",
      "Train Epoch: 3 [1200/1773 (67%)]\tLoss: 1.365225\n",
      "Train Epoch: 3 [1350/1773 (75%)]\tLoss: 1.378489\n",
      "Train Epoch: 3 [1500/1773 (83%)]\tLoss: 1.382361\n",
      "Train Epoch: 3 [1650/1773 (92%)]\tLoss: 1.359583\n",
      "train loss: 1.3435, Accuracy: 962/1773 (54%)\n",
      "validation loss: 1.3852, Accuracy: 96/342 (28%)\n",
      "\n",
      "Train Epoch: 4 [0/1773 (0%)]\tLoss: 1.356530\n",
      "Train Epoch: 4 [150/1773 (8%)]\tLoss: 1.349077\n",
      "Train Epoch: 4 [300/1773 (17%)]\tLoss: 1.365143\n",
      "Train Epoch: 4 [450/1773 (25%)]\tLoss: 1.352329\n",
      "Train Epoch: 4 [600/1773 (33%)]\tLoss: 1.327744\n",
      "Train Epoch: 4 [750/1773 (42%)]\tLoss: 1.340919\n",
      "Train Epoch: 4 [900/1773 (50%)]\tLoss: 1.346703\n",
      "Train Epoch: 4 [1050/1773 (58%)]\tLoss: 1.356364\n",
      "Train Epoch: 4 [1200/1773 (67%)]\tLoss: 1.334735\n",
      "Train Epoch: 4 [1350/1773 (75%)]\tLoss: 1.362451\n",
      "Train Epoch: 4 [1500/1773 (83%)]\tLoss: 1.349073\n",
      "Train Epoch: 4 [1650/1773 (92%)]\tLoss: 1.372406\n",
      "train loss: 1.3327, Accuracy: 474/1773 (27%)\n",
      "validation loss: 1.3875, Accuracy: 87/342 (25%)\n",
      "\n",
      "Train Epoch: 5 [0/1773 (0%)]\tLoss: 1.361487\n",
      "Train Epoch: 5 [150/1773 (8%)]\tLoss: 1.351520\n",
      "Train Epoch: 5 [300/1773 (17%)]\tLoss: 1.314355\n",
      "Train Epoch: 5 [450/1773 (25%)]\tLoss: 1.340799\n",
      "Train Epoch: 5 [600/1773 (33%)]\tLoss: 1.314572\n",
      "Train Epoch: 5 [750/1773 (42%)]\tLoss: 1.302284\n",
      "Train Epoch: 5 [900/1773 (50%)]\tLoss: 1.334145\n",
      "Train Epoch: 5 [1050/1773 (58%)]\tLoss: 1.342464\n",
      "Train Epoch: 5 [1200/1773 (67%)]\tLoss: 1.334581\n",
      "Train Epoch: 5 [1350/1773 (75%)]\tLoss: 1.338092\n",
      "Train Epoch: 5 [1500/1773 (83%)]\tLoss: 1.335729\n",
      "Train Epoch: 5 [1650/1773 (92%)]\tLoss: 1.368709\n",
      "train loss: 1.3168, Accuracy: 1053/1773 (59%)\n",
      "validation loss: 1.3877, Accuracy: 87/342 (25%)\n",
      "\n",
      "Train Epoch: 6 [0/1773 (0%)]\tLoss: 1.299927\n",
      "Train Epoch: 6 [150/1773 (8%)]\tLoss: 1.317165\n",
      "Train Epoch: 6 [300/1773 (17%)]\tLoss: 1.343089\n",
      "Train Epoch: 6 [450/1773 (25%)]\tLoss: 1.295494\n",
      "Train Epoch: 6 [600/1773 (33%)]\tLoss: 1.311943\n",
      "Train Epoch: 6 [750/1773 (42%)]\tLoss: 1.306517\n",
      "Train Epoch: 6 [900/1773 (50%)]\tLoss: 1.320213\n",
      "Train Epoch: 6 [1050/1773 (58%)]\tLoss: 1.302238\n",
      "Train Epoch: 6 [1200/1773 (67%)]\tLoss: 1.327727\n",
      "Train Epoch: 6 [1350/1773 (75%)]\tLoss: 1.321899\n",
      "Train Epoch: 6 [1500/1773 (83%)]\tLoss: 1.343961\n",
      "Train Epoch: 6 [1650/1773 (92%)]\tLoss: 1.320213\n",
      "train loss: 1.3053, Accuracy: 584/1773 (33%)\n",
      "validation loss: 1.3963, Accuracy: 87/342 (25%)\n",
      "\n",
      "Train Epoch: 7 [0/1773 (0%)]\tLoss: 1.282680\n",
      "Train Epoch: 7 [150/1773 (8%)]\tLoss: 1.300176\n",
      "Train Epoch: 7 [300/1773 (17%)]\tLoss: 1.305664\n",
      "Train Epoch: 7 [450/1773 (25%)]\tLoss: 1.324543\n",
      "Train Epoch: 7 [600/1773 (33%)]\tLoss: 1.316511\n",
      "Train Epoch: 7 [750/1773 (42%)]\tLoss: 1.298076\n",
      "Train Epoch: 7 [900/1773 (50%)]\tLoss: 1.292486\n",
      "Train Epoch: 7 [1050/1773 (58%)]\tLoss: 1.358179\n",
      "Train Epoch: 7 [1200/1773 (67%)]\tLoss: 1.307486\n",
      "Train Epoch: 7 [1350/1773 (75%)]\tLoss: 1.288063\n",
      "Train Epoch: 7 [1500/1773 (83%)]\tLoss: 1.289075\n",
      "Train Epoch: 7 [1650/1773 (92%)]\tLoss: 1.308324\n",
      "train loss: 1.2801, Accuracy: 1231/1773 (69%)\n",
      "validation loss: 1.3909, Accuracy: 82/342 (24%)\n",
      "\n",
      "Train Epoch: 8 [0/1773 (0%)]\tLoss: 1.287726\n",
      "Train Epoch: 8 [150/1773 (8%)]\tLoss: 1.267908\n",
      "Train Epoch: 8 [300/1773 (17%)]\tLoss: 1.280428\n",
      "Train Epoch: 8 [450/1773 (25%)]\tLoss: 1.277165\n",
      "Train Epoch: 8 [600/1773 (33%)]\tLoss: 1.269975\n",
      "Train Epoch: 8 [750/1773 (42%)]\tLoss: 1.233403\n",
      "Train Epoch: 8 [900/1773 (50%)]\tLoss: 1.320568\n",
      "Train Epoch: 8 [1050/1773 (58%)]\tLoss: 1.293365\n",
      "Train Epoch: 8 [1200/1773 (67%)]\tLoss: 1.186607\n",
      "Train Epoch: 8 [1350/1773 (75%)]\tLoss: 1.334014\n",
      "Train Epoch: 8 [1500/1773 (83%)]\tLoss: 1.288181\n",
      "Train Epoch: 8 [1650/1773 (92%)]\tLoss: 1.297695\n",
      "train loss: 1.2623, Accuracy: 1156/1773 (65%)\n",
      "validation loss: 1.3990, Accuracy: 82/342 (24%)\n",
      "\n",
      "Train Epoch: 9 [0/1773 (0%)]\tLoss: 1.224838\n",
      "Train Epoch: 9 [150/1773 (8%)]\tLoss: 1.287218\n",
      "Train Epoch: 9 [300/1773 (17%)]\tLoss: 1.249177\n",
      "Train Epoch: 9 [450/1773 (25%)]\tLoss: 1.250975\n",
      "Train Epoch: 9 [600/1773 (33%)]\tLoss: 1.265318\n",
      "Train Epoch: 9 [750/1773 (42%)]\tLoss: 1.240103\n",
      "Train Epoch: 9 [900/1773 (50%)]\tLoss: 1.240316\n",
      "Train Epoch: 9 [1050/1773 (58%)]\tLoss: 1.272312\n",
      "Train Epoch: 9 [1200/1773 (67%)]\tLoss: 1.260688\n",
      "Train Epoch: 9 [1350/1773 (75%)]\tLoss: 1.206751\n",
      "Train Epoch: 9 [1500/1773 (83%)]\tLoss: 1.262864\n",
      "Train Epoch: 9 [1650/1773 (92%)]\tLoss: 1.282403\n",
      "train loss: 1.2265, Accuracy: 1057/1773 (60%)\n",
      "validation loss: 1.3948, Accuracy: 87/342 (25%)\n",
      "\n",
      "Test set result:\n",
      "validation loss: 1.4120, Accuracy: 94/443 (21%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAEICAYAAACphgboAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xd8VFX6+PHPk0JCqAkphF6kRqkBCxbsoAgWVsEKgqy6rquufnV/W+y7ukVZ17IqsthAWXvBLooFFXQxIEUIJBAgBFJoSSDl/P44M2EIk2SS3Jk7SZ7365XXZO69c+9JYPLMuec5zxFjDEoppZRq2iLcboBSSimlGk8DulJKKdUMaEBXSimlmgEN6EoppVQzoAFdKaWUagY0oCullFLNgAZ05ZeIZInIGW63QymlVGA0oCullFLNgAZ0pZRSNRJLY0UToP9IqlYiEiMis0Vkm+drtojEePYlisg7IlIkIgUi8oX3jS8it4vIVhHZKyLrROR0d38SpZo2EblDRDI976nVInKBz75rRGSNz74Rnu3dReQ1EdkpIvki8qhn+10i8oLP63uJiBGRKM/zz0TkfhH5CigG+ojIdJ9rbBSRX1Zr3yQRWSEiezztHCcivxCR76sd91sReSN4v6mWK8rtBqiw93vgOGAYYIA3gT8AfwR+C+QASZ5jjwOMiAwAbgBGGWO2iUgvIDK0zVaq2ckETgJygV8AL4jIUcCJwF3A+cByoC9QJiKRwDvAp8AVQAWQXo/rXQGMB9YBAgwAJgAbgZOB90RkmTHmBxEZDTwHTAY+AVKBdsAm4EkRGWSMWeM57+XAfQ35BajaaQ9d1eUy4B5jTJ4xZidwN/aNDlCGfeP2NMaUGWO+MHZxgAogBhgsItHGmCxjTKYrrVeqmTDG/NcYs80YU2mMeRlYD4wGZgJ/NcYsM9YGY0y2Z18X4DZjzH5jTKkx5st6XHKeMeYnY0y55/39rjEm03ONz4EPsR8wAGYAc40xH3nat9UYs9YYcwB4GRvEEZE0oBf2g4ZymAZ0VZcuQLbP82zPNoC/ARuADz234O4AMMZsAG7C9hryROQlEemCUqrBRORKzy3tIhEpAo4GEoHu2N57dd2BbGNMeQMvuaXa9ceLyDee4bUi4BzP9b3XqulD+7PApSIi2M7AQk+gVw7TgK7qsg3o6fO8h2cbxpi9xpjfGmP6AOcBt3jHyo0x840xJ3pea4AHQ9tspZoPEekJPI0dyupkjOkIrMLeCt+Cvc1e3Ragh3dcvJr9QJzP885+jqlaitOTN/Mq8HcgxXP9RZ7re6/lrw0YY74BDmJ785cCz/v/KVVjaUBXdVkA/EFEkkQkEfgT8AKAiEwQkaM8n7z3YG+1V4jIABE5zfNHoBQo8exTSjVMG2yA3QkgItOxPXSAOcCtIjLSk5F+lOcDwHfAduABEWkjIrEiMsbzmhXAySLSQ0Q6AL+r4/qtsMNoO4FyERkPnOWz/xlguoicLiIRItJVRAb67H8OeBQor+dtf1UPGtBVXe7DJtpkACuBHziU0NIP+BjYBywFHjfGfIZ94z8A7MIm8CQD/y+krVaqGTHGrAb+gX2f7QCOAb7y7PsvcD8wH9gLvAEkGGMqsHfOjgI2YxNYL/G85iPs2HYG8D11jGkbY/YCNwILgUJsT/stn/3fAdOBh4HdwOccfmfveewHEO2dB5HYHCallFIqOESkNZAHjDDGrHe7Pc2V9tCVUkoF23XAMg3mwaXz0JVSSgWNiGRhk+fOd7kpzZ7ecldKKaWaAb3lrpRSSjUDTeqWe2JiounVq5fbzVAq7H3//fe7jDFJdR/pDn0vKxWY+ryXm1RA79WrF8uXL3e7GUqFPRHJrvso9+h7WanA1Oe9rLfclVJKqWZAA7pSSinVDGhAV0oppZqBJjWGrpQKPREZB/wTu6b9HGPMA9X2Pwyc6nkaByR7Fu+ol7KyMnJycigtLW1sk5VHbGws3bp1Izo62u2mqBAIKKCLyFzswvZ5xpijazluFPANcIkx5hXPtquAP3gOuc8Y86xn+0hgHtAau2rPb4xOilcqrIhIJPAYcCa2FvgyEXnLU1scAGPMzT7H/xoY3pBr5eTk0K5dO3r16oVd70c1hjGG/Px8cnJy6N27t9vNUSEQ6C33ecC42g7wvPEfBD7w2ZYA3AkcC4wG7hSReM/uJ4BZ2AU++tV1fqWUK0YDG4wxG40xB4GXgEm1HD8Vu0JfvZWWltKpUycN5g4RETp16qR3PFqQgAK6MWYJUFDHYb/Grpeb57PtbOAjY0yBMaYQ+AgYJyKpQHtjzFJPr/w5tCygUuGoK3ata68cz7YjeJbs7A18WsP+WSKyXESW79y50+/FNJg7S3+fLYsjSXEi0hW4APh3tV01/THo6vm++nZ/567zj4BS4aay0rB4bR5zv9zE/zYXcrC80u0mNZS/iFDT0NgU4BXPsp1HvsiYp4wx6caY9KSksK15o5qDvDXw0xtutyLknMpynw3c7ueNXNMfg4D/SOgfAdWUlJZVMP/bzZz58OdMn7eMe95ZzQWPf80xd33AxU8u5a/vr+XTtTsoKj7odlMDlQN093neDdhWw7FTaODt9qaqbdu2AGzbto3Jkyf7PWbs2LF1FtGZPXs2xcXFVc/POeccioqKnGtoS7Pkb/Dfq+DDP0Blk/0wXW9OZbmnAy95bu8kAueISDn2j8FYn+O6AZ95tnertr2mPxJKhb1d+w7w/NJsXvgmm/z9B0nr0p7ZlwxjdO8EVmwpYnlWId9nF/DUko08/pn97NovuS3pveIZ2TOB9J7x9OwUF463SJcB/USkN7AVG7QvrX6QiAwA4oGloW1eeOjSpQuvvPJKg18/e/ZsLr/8cuLi4gBYtGiRU01rmQo2QVQsfP0v2LsDJj0GUa3cblXQORLQjTFVKZQiMg94xxjzhicp7s8+iXBnAb8zxhSIyF4ROQ74FrgS+JcTbVEtw9rcPWTnF3N83060j3VvSs6GvH088+UmXv0hh4PllZw2MJmZJ/Xm+D6Hkru6dGzNOcekAlBysIIVW4r4PruA5dmFvJOxnQXf2VGpxLYxjOzZkfSeCaT3iietSwdaRblbKsIYUy4iN2CTXSOBucaYn0TkHmC5MeYtz6FTgZea+kyV22+/nZ49e3L99dcDcNdddyEiLFmyhMLCQsrKyrjvvvuYNOnwvMCsrCwmTJjAqlWrKCkpYfr06axevZpBgwZRUlJSddx1113HsmXLKCkpYfLkydx999088sgjbNu2jVNPPZXExEQWL15cVRo3MTGRhx56iLlz5wIwc+ZMbrrpJrKyshg/fjwnnngiX3/9NV27duXNN9+kdevWoftlhbOibBg6BTp0h0/vhf074ZLnIaad2y0LqkCnrS3A9rQTRSQHm7keDWCMqT5uXsUTuO/FfsoHuMcY402uu45D09be83wpVavvswt4bHEmn661uZdREcLo3gmcNjCZMwal0CuxTdDbYIzhm40FzPliI5+szaNVVAQXjejKjBN7c1Ry7X8wWreK5Pi+nTi+byfAjrWvz9vH8uwCvs8qZHl2IR/8tAOAmKgIhnbvSHrPeNJ7xTOiRzwd40LfyzDGLMJOLfXd9qdqz+9y8pp3v/0Tq7ftcfKUDO7SnjvPS6v1mClTpnDTTTdVBfSFCxfy/vvvc/PNN9O+fXt27drFcccdx8SJE2u8m/LEE08QFxdHRkYGGRkZjBgxomrf/fffT0JCAhUVFZx++ulkZGRw44038tBDD7F48WISExMPO9f333/Pf/7zH7799luMMRx77LGccsopxMfHs379ehYsWMDTTz/NxRdfzKuvvsrll1/eyN9SM3BgHxTnQ8eecNIt0K4zvHUjzDsXLnsF2ia73cKgCSigG2OmBnpCY8y0as/nAnP9HLccqHFOu1Jexhi+3LCLRz/dwLebCoiPi+a3Z/ZnZK94lvy8i0/X7uC+d9dw37tr6JPUhtMHJnP6oBRG9ownOtK5Hm5ZRSWLVm7n6S82smrrHhLatOI3p/fjiuN7ktg2pkHnjIgQBnRux4DO7bjs2J4A5O0p5fvsQpbVcJv+1rMHcHZaZ8d+LnXI8OHDycvLY9u2bezcuZP4+HhSU1O5+eabWbJkCREREWzdupUdO3bQubP/f4MlS5Zw4403AjBkyBCGDBlStW/hwoU89dRTlJeXs337dlavXn3Y/uq+/PJLLrjgAtq0sR9UL7zwQr744gsmTpxI7969GTZsGAAjR44kKyvLod9CE1fkWcsk3r6fGH45tEmChVfBM2fC5a9Bp77utS+ItFKcCluVlYYPV+/g8c82kJGzm5T2Mfzh3EFcemwP4lrZ/7on9E3kjvED2ZxfzKdrd/DJ2jzmfZ3F019son1sFKcMSOaMQcmc0j+pwb3bPaVlvPTdZuZ9lcW23aX0SWrDny84hgtHdCU2OtLJHxmA5PaxjD8mlfE13KZvF9P837Z19aSDafLkybzyyivk5uYyZcoUXnzxRXbu3Mn3339PdHQ0vXr1qnNut7/e+6ZNm/j73//OsmXLiI+PZ9q0aXWep7YRjJiYQx8iIyMjD7u136IVegJ6x16HtvU/G6a9Ay/+Ap45Cy5bCF1HutK8YGr+fxlUk1NeUcnbGdt4fHEm6/P20SMhjr9caANoTJT/ANqjUxzTxvRm2pje7DtQzpfrd/LJmjwWr8vj7R+3ERkhjOwZ7+m9J9M3qW2dCWhbi0r4z5ebeGnZFvYdKOe4Pgnce/7RnDogmYiI0CWvVb9Nr4JrypQpXHPNNezatYvPP/+chQsXkpycTHR0NIsXLyY7u/bVLE8++WRefPFFTj31VFatWkVGRgYAe/bsoU2bNnTo0IEdO3bw3nvvMXbsWADatWvH3r17j7jlfvLJJzNt2jTuuOMOjDG8/vrrPP/880H5uZuN6j10r27pMONDeOFCmHceXPwc9Dsj9O0LIg3oKmyUllXwyvc5PLkkky0FJQxIacc/pwzj3GNSiarHrfO2MVGMOzqVcUenUllp+DGniE/X5vHxmjz+8t5a/vLeWnp2iuO0gcmcPjCF0b0TDks+y8gp4ukvNrFo5XYAJgxJZeaJfTimWwfHf2YVftLS0ti7dy9du3YlNTWVyy67jPPOO4/09HSGDRvGwIEDa339ddddx/Tp0xkyZAjDhg1j9OjRAAwdOpThw4eTlpZGnz59GDNmTNVrZs2axfjx40lNTWXx4sVV20eMGMG0adOqzjFz5kyGDx+ut9drU5gN0W0gzs8H4MR+MOMjeHEyLLjEZr8PnRL6NgaJNKWk1PT0dFPXfE7V9Ow/UM78bzfz9Bcbydt7gGHdO3LDqUdx2kDne8Lbikr4dG0en6zZwVeZ+Rwsr6RtTBQn908kvWcC7/+Uy3ebCmgXE8WU0d2ZNqY3XTs2vcxhEfneGJPudjtq4u+9vGbNGgYNGuRSi5qvFvd7XTAVCrPg+lpmUJbugZcvg01L4Iy7YcxvIPymjAL1ey9rD125pqj4IPO+zmLe11kUFZcx5qhOzL5kGMf3DV497y4dW3P5cT25/LieFB8s5+sN+XyyNo9P1+5g0cpcunZszR/OHcQlo7rTzsXpcEqpBirMthnutYltbzPe37gOPr4T9m6Hs/8CEU17RXEN6Crk8vaU8syXm3jhm2z2H6zgzMEpXD+2L8N7xNf9YgfFtYrijMEpnDE4BWOOZnNBMV07tq7X7X2lVBgxxo6h9z6p7mOjYuDCOdA2Bb55HPbtgAuetNubKA3oKmS2FBTz5JJMFi7PobyikvOGduG6sX0Z2Lm9201DROjZKfhz2JVSQVRcAAf31d1D94qIgLP/DO1S4aM/wv5dMOVFiG2a+TIa0FWVfQfK2VJQzOaCYvL3HaTCGCorDZXGUFH1SNXzikqDMYYKP9srjc/xlYbC4oN8sjaPSBEuGtmNa0/powFUKeWsoiz7WD3DvTYiMOZG21N/83r4zzn2dnz71KA0MZiaVUAv3H+Q0vIKYqIiaRUVQUxUBFEREo71sV1RXlHJ9t2lVUF7c0ExWwpL7GNBMQX7679giAhEihARIUT4fB8ZIYe+FyE6Sph2Qi+uOakPnTvEBuGnU0q1eFVz0OsR0L2GXgJtEmHhlXau+hWv2az4JqRZBfSHP/6Z55YePkc0QiAmKpKYaBvgfYO997nvvpioCM/+Q9ujI+0Hg6jICKIjhagI+xgdGUGUz/OoyAiiPcdFRQrREZ5H7zFRh++Pijj0Wic+dBhjKCou8wTq4qpAvaXABu2tRSVUVB6a1RAVIXSNb02PhDjOTutMj4Q4eiTE0T2hNUntYqqCcqTnQ9GhIM1h25VSKizUNAc9UEed7lOA5ky4dCF0H+1c+4KsWQX084d3ZXBqew6UV3KgvIIDZZVV3x8s935/5L7i/eWH9pVVHHZcWUVopvVFRtgAX/1DQqR322EfKA7/cBEhsGPPAbYUFLP3QPlh501s24pu8XEM696RiUO70D2hNd09gbtz+1hNAFPKR1FREfPnz6+q5R6oc845h/nz59OxY8cgtUwFpDALWic0bhGWLsNtAZrnL4RnJ8Iv5sGAcU61MKiaVUAf0cMuYOGkykpDWWUl5RWG8grDwYpKyj3PyyoqKa/0PFYYyisrKfMcd+g1lZRVGsrKK33229eVV3r2e15rz3noPBXebX6Pq+RAWSX7KiuoqKykc4dYRvdOoHtCHN3jW9OjUxzd4+No0wLKhCrllKKiIh5//PEjAnpFRQWRkTWX+dXlTsNEYTbE92r8eRL6HCpA89KlcN5sGHFl488bZPrXvg4REUJMRCQaF5Vq/u644w4yMzMZNmwY0dHRtG3bltTUVFasWMHq1as5//zz2bJlC6WlpfzmN79h1qxZAFXLne7bt0+XNXVTUTakDnXmXG2TYNq7dkz9rV/bddVPvjVsC9CABnSlVDh67w7IXensOTsfA+MfqPWQBx54gFWrVrFixQo+++wzzj33XFatWkXv3r0BmDt3LgkJCZSUlDBq1CguuugiOnU6vMSoLmvqksoKKNoCgyY6d86YtnDpy/DmDbD4PjCVMPZ2587vMA3oSilVg9GjR1cFc4BHHnmE119/HYAtW7awfv36IwK6Lmvqkr3bobKs4QlxNYmMhgv+bXvmn/3ZLr16zGRnr+EQDehKqfBTR086VLzrkAN89tlnfPzxxyxdupS4uDjGjh3rd/lTXdbUJY2ZslYXETjvnzbp7o3r7TW6j3L+Oo3U/FKcm9BiM0qp8OJdxtSf3bt3Ex8fT1xcHGvXruWbb74JcetUraqmrPUKzvmjYuCSF23BmZemQtHm4FynEZpXQP/+WZuRWFLkdkuUUk1Qp06dGDNmDEcffTS33XbbYfvGjRtHeXk5Q4YM4Y9//CPHHXecS61UfhVmAwIdugXvGm062bnp5Qdh/hQ44P/Dn1ua1y33ioOw/kN4+lT7SSplsNstUko1MfPnz/e7PSYmhvfee8/vPu84eWJiIqtWrarafuuttzrePlWDomxo3yX4i6skDYCL58ELk+GVGTB1AUTUPKUxlJpXD330NXDVO3BwP8w5HVa+4naLlFJKhUIgy6Y6pe9pcM7fYP0H8OEfQ3PNANQZ0EVkrojkiciqGvZPEpEMEVkhIstF5ETP9lM927xfpSJyvmffPBHZ5LNvmGM/Uc/j4ZdL7FzEV2fY6S8VZY6dXimlVBgqynY+w702o2bAsdfBN4/B8rmhu24tAumhzwNqq3v3CTDUGDMMuBqYA2CMWWyMGebZfhpQDHzo87rbvPuNMSsa1PqatOsMV70Nx14L3z4Bz54He3MdvYRSynlGk1od1WJ+n+UHYM+20PXQvc6+H/qdBe/eCpmLQ3ttP+oM6MaYJUBBLfv3mUP/a9oA/v4HTQbeM8YUN6iVDREZDeMftAvYb/8RnjwFNmtWqlLhKjY2lvz8/JYThILMGEN+fj6xsS1gdcPdOYAJbQ8d7Nj5Rc/YcfWFV8HOn0N7/WocSYoTkQuAvwDJwLl+DpkCPFRt2/0i8idsD/8OY8yBGs49C5gF0KNHj/o3bsgvbHLcy5fDvHPhrPvh2F+Gdfk+pVqibt26kZOTw86dO91uSrMRGxtLt25BzPoOF4VZ9jHUPXSA2PYw9SWbtzX/Ypj5ic2Gd4EjAd0Y8zrwuoicDNwLnOHdJyKpwDHABz4v+R2QC7QCngJuB+6p4dxPeY4hPT29YR/dU9LgmsXw+rXw/u2wdbktEtCqTd2vVUqFRHR09GFV2ZQKWGOXTW2s+J4wZT7Mm2A7j1e+Efxsez8czXL33J7vKyKJPpsvBl43xpT5HLfdWAeA/wDBX3C2dUf7Cz/tDzb7fc6ZkJ8Z9MsqpZQKssJsiIiGdqnutaH7aDj/cdj8Nbx9kytFzhod0EXkKBF7/1pERmB73fk+h0wFFlR7TarnUYDzAb8Z9I6LiICTb4PLX4G92+CpU2Gd/3mlSimlmojCLOjY3f354MdMhlPugB/nw1ezQ375QKatLQCWAgNEJEdEZojItSJyreeQi4BVIrICeAy4xJskJyK9gO7A59VO+6KIrARWAonAfU78MAE76gyY9Tkk9IIFU+DT++xKPUoppZqeIofWQXfC2Dvg6Ivg47tg9VshvXSdY+jGmKl17H8QeLCGfVlAVz/bTwuwfcET3xOu/sBON1jyN9j2P7jwaYhLcLtlSiml6qMwG1KdK2fSKCIw6XFb6/21WfbOQZfhIbl086oUV1/RrWHSozBhNmxaAk+dAtucnRKvlFIqiA7shZIC9xLi/ImOtTlbbRJhwVQ7Rz4EWnZAB/tpKn06TH/f3nafezb870W3W6WUUioQwVw2tTHaJsOlL9sPHAum2JLkQaYB3avbSFsytvtoePN6eOdmW31IKaVU+HJ7ylptUtJg8lzIXWlvv1dWBvVyGtB9tUmEy1+HMTfZ2rz/OQd2b3W7VUoppWpS1UPv5WozatT/bDj7z7D2Hfjk7qBeSgN6dZFRcObdcPHzsHMtPHkyLHsGDuxzu2VKuUJExonIOhHZICJ31HDMxSKyWkR+EhH/648qFQxF2dCqbXgnNB97LaRfbaey/e+FoF1GA3pNBk+01eU69oB3b4GHBsGi/3O9Vq9SoSQikdjpqOOBwcBUERlc7Zh+2OqPY4wxacBNIW+oarm8y6aGczlvERj/V+gz1hadyfoyKJfRgF6bpP5wzacw4yPoP87ehn9sFDw7Eda8AxXlbrdQqWAbDWwwxmw0xhwEXgImVTvmGuAxY0whgDEmL8RtVC1ZqJdNbajIaPjFs5DQ25aHDUKlUg3odRGxiXIXPQ23rIHT/mj/IV6+DP45FJb8HfbpYhKq2eoKbPF5nsORtSX6A/1F5CsR+UZE/C63LCKzRGS5iCzXBViUI4w51ENvClp3tJnvCMy/BEoKHT29BvT6aJsEJ98Kv/kRLnkREo+CT++FhwfDq9fAlu9cqd+rVBD5u49Z/T95FNAPGIst9TxHRDoe8SJjnjLGpBtj0pOSkhxvqGqBivOhbH/T6KF7JfSBKS/acrULr4KKsjpfEigN6A0RGQWDJsCVb8KvlsHI6fDz+/DMmTaJ7ofn4GDoln5XKohysOWbvboB1atk5ABvGmPKjDGbgHXYAK+ao4z/wqLb3G6FFa5z0OvS8wSY+Ah06uvoaTWgN1ZSfzjnr/Z2/LkPQWU5vPVrm0T3we91RTfV1C0D+olIbxFpBUwBqheofgM4FcCz0mJ/YGNIW6lCZ+V/7cyfcKjTUZRlH5tSD91r2KUw4WE7tu4QDehOiWkLo2bAdV/DtEXQ91T49t/wrxHwwkWw7n1dAEY1OcaYcuAG4ANgDbDQGPOTiNwjIhM9h30A5IvIamAxcJsxJt//GVWTV5AJpgJ2rnO7JU23hx4kdS7OoupJBHqNsV97tsMPz8Ly/8CCS+x/uvSrYcSV4T1nUikfxphFwKJq2/7k870BbvF8qeasotyO/QLs+AlSh7jaHAqzIK6T7VAp7aEHVftUu5TezavgF/OgQ3f4+E54ZDis/9jt1imlVP3s3myHFQF2rHK3LWCnrGnvvIoG9FCIjIa0C2D6u3DtV9ChG7w42U5506x4pVRTke9JjYiIhrzV7rYF7C33cFkHPQxoQA+1zkfDjA/h6IvslLeXL4fSPW63Siml6lbgSfLtc4q95e6mygrYndM0E+KCRAO6G1q1gYvmwNl/gXXvwZzTtaSsUir85Wfauul9ToV9O2D/LvfasmcbVJbpLXcfGtDdIgLHX2/nshcXwNOnwZq33W6VUkrVrCDTFkZJSbPP3eylh/OyqS7RgO623ifZddiT+tvb75/co9PblFLhKT+MArpOWTtCQAFdROaKSJ6I+E1rFJFJIpIhIis8tZpP9NlX4dm+QkTe8tneW0S+FZH1IvKyp2hFy9ShK0x/z05n++If8OIvbK9dKaXCRUUZFG221c3aJkObJMhzu4cudvaQAgLvoc8D/C644PEJMNQYMwy4Gpjjs6/EGDPM8zXRZ/uDwMPGmH5AITAj8GY3Q1ExMPFfcN4/IesLeGos5K50u1VKKWUVbbYFZRI85UpT0tzvobfvClEtty9YXUAB3RizBKixy2iM2ecpLgHQhiMXbziMiAhwGvCKZ9OzwPmBtKXZGznN9tYrymDOmZCx0O0WKaXUoTLW3vrjyWmQt9a9IcKmsmxqCDk2hi4iF4jIWuBdbC/dK9ZzG/4bEfEG7U5AkaesJPhfktF73pa35GK3dPjl59B1BLx2Dbx3h6Mr8iilVL15p6z59tDLS6BgkzvtaUrLpoaIYwHdGPO6MWYgtqd9r8+uHsaYdOBSYLaI9CWwJRm9522ZSy62TbYZ8MddD98+Ac9Ngn15brdKKdVS5WdCTHtok2ifpwy2j25UjCs/AHu3aw+9Gsez3D235/t6Vl3CGLPN87gR+AwYDuwCOoqIt5a8vyUZVWQ0jPsLXPg0bP0BnjwFcpa73SqlVEvknbImnv5Y0kCQCHcqxhVtAYz20KtxJKCLyFGecXFEZATQCrv6UryIxHi2JwJjgNWe8fbFwGTPKa4C3nSiLc3SkIttdbnIaPjPeLvYi1JKhVJ+5uHrd0e3hk4ygq8mAAAgAElEQVRHuZMY15SXTQ2iQKetLQCWAgNEJEdEZojItSJyreeQi4BVIrICeAy4xBO0BwHLReRHbAB/wBjj/Th3O3CLiGzAjqk/49yP1QylDoFZn0Gvk+Cdm+ya6+GwHrFSqvkrPwi7txwaP/dKHuzOLXedg+5XQMunGmOm1rH/Qew0tOrbvwaOqeE1G4HRgVxfecQlwGX/hcV/hi/+bj8ZX/ycXexFKaWCpTALTOXhPXSAlKNh9RtwYF9olzAtyobIVtAuNXTXbAK0UlxTExEJp/8RLnnB1n9/8hTI+tLtVikV/go2QeZit1vRNFXPcPfyVozLWxPa9hRm2YIyERrCfOlvo6kadB5c86nttT870ZaMPVjsdquUCl+L77dVGPdsd7slTU/1Oehe3kz3UFeMK9Q56P5oQG/KkvrDzE9s0twX/4DHjoU17+ga60r5s/1HuzrXd0+53ZKmpyATYjvaDoSvDj2gVbvQJ8YV6Rx0fzSgN3Wx7eGCf8O0RXYM6+XLYP7FULDR7ZYpFT4O7odd60EiYflc+zwc7VgNaxe53YojVc9w94qIgORBoQ3opXugpBDie4Xumk2EBvTmotcYu2rb2X+G7KXw2HGw+C9QVuJ2y5Ry347VgIHjfwWlRbBivtstOpIx8NoseHUmVFa63ZrDFWw8cvzcy1vTPVR3BnXZ1BppQG9OIqPtH6wbltkx9s8fsLfh173vdsuUclduhn0cNRO6jYJvHg+/ZYrXfwQ7VkLZfti92e3WHFJWCrtz/PfQwQb00iLYE6LaYDplrUYa0Juj9qkw+Rm46m2IioUFl8D8KTYzVKmWKDcDYjtAxx72Q2/BRlj3ntutOsQYOxU1MsY+D3XWeG0KNwGm9h46hK5iXFUPvVdorteEaEBvznqfDNd+CWfeC5uW2N7653+1n7iVaklyV0LnIbZs6cDzbGBf+pjbrTok+2vY8i2Mvd0+d6Ocak2qMtz7+N+fHOKa7oXZNhGvdXxorteEaEBv7qJawZgb7W34AePt1J0njof1H7vdMqVCo6LcjvF2HmKfR0bBsdfB5q9h6/futs3ri79DmyS7GFOH7uHVQ6+ag15DQG/dEdp3C11inHfZVPG3xlfLpgG9pejQFX4xD6543S6o8OJF8NJlUBRGY3VKBUP+Bigvhc4+RSuHX25XDguHXvrWHyDzUzsUEN3aZo3nrXW7VYcUbITWCbX3iFPSPImHIaDLptZIA3pL0/c0uO5rOP1O+0fk0dGw5O9aF141X96EuNQhh7bFtoeRV8FPb3hW7nLRlw/Z8f30GfZ58iDYtc7eWQgHNU1Z85WSZttcfjC4bTHmUA9dHUEDeksUFQMn3QK/+g76nQGf3gtPnGADvFLNTW6GTTZL7H/49tG/tI/f/jv0bfLKWwtr3rZtiW1vtyUPhoqD4VNLorYpa14paVBZDvnrg9uW/bugrFh76DXQgN6Sdexua8Jf9qpdeOH5C2DhVbB7q9stU8o52zNsrzcy+vDtHbtD2gXww3O2WIkbvnwYouPg2GsPbUseZB/DITHuYDHs2RpYDx2CP46uc9BrpQFd2V76dUvh1D/Az+/Do6Ng6eNaQlY1fcZ4Mtz9Lvpox60P7IH/vRDadoGdRrryvzByOrTpdGh7Yn+b5xIOiXGFm+xjTQlxXp2Ogojo4Ge6e6feag/dLw3oyoqOhVNus7fhe58EH/wO3v5N+IzjKdUQe7ZCSQGkDvW/v+sI6HECfPNE6P+vf/WIXT3xhBsO3x7dGuJ7h0cPvaZFWaqLjIakgcFPjPP20Dv2CO51migN6Opw8T1h6ktw0m/hh2dtbfhwrXutVF1yV9rHmnroYAPq7s2w9u3QtAlgb669KzDsUmjf5cj9yYNgZxhkute0bKo/3hKwwVSYDXGJoV17vQnRgK6OJAKn/wnOfQjWfwjPnmeTUZRqarZnAHJojNef/uPsLeWvHw3dMNPSx+zKb2N+439/8mDbO3a7CFR+pp0f703Yq03KYNi7DYoLgteewiwdP6+FBnRVs1EzbNLcjp/gmTPDJ+tWqUDlZthgHdOu5mMiIm1Bl63LYct3wW9TcYFd8e3oi2oem04eBKYi+FnjdQkkw90rFCVgddnUWmlAV7UbeK6tCV9SBHPODJ/KWkoFIjfj8PnnNRl2qV3ve+mjwW/Td0/BwX1w4i01H+Mtp+p2Ylwgc9C9koOc6V5ZYReJ0R56jTSgq7p1Hw0zPoRWcTBvAvz8gdstUqpuJUW2EmJt4+derdpA+tWw9h0o2BS8Nh3YaxPwBpxrb1HXpFNfmzXuZmLcgX2wL7fuDHevdp1tRblgBfQ9W+1cd12UpUZ1BnQRmSsieSLidz6CiEwSkQwRWSEiy0XkRM/2YSKyVER+8uy/xOc180Rkk+c1K0RkmHM/kgqKxH4w42P7uGCqnburWgQRGSci60Rkg4jc4Wf/NBHZ6fN+nulGO49QlRBXQ4Z7daNngUQGt9DM9/PsUqMn1dI7B5s1ntjP3R66d4gt0B66SHAT43TZ1DoF0kOfB4yrZf8nwFBjzDDgamCOZ3sxcKUxJs3z+tki0tHndbcZY4Z5vlbUv+kq5NqlwLR3oc9YeOvX8NkDOle9mRORSOAxYDwwGJgqIv66li/7vJ/n+NkfeoFkuPtqnwrHTIYfnoeSQufbU1YKX/8Lep8C3dLrPj55kMsBvR4Z7l4pabbNlZXOt0eLytSpzoBujFkC1Ji2aIzZZ0zVX/U2gPFs/9kYs97z/TYgD0hqdIuVu2LawaUvw9BL4bO/wNs36lz15m00sMEYs9EYcxB4CZjkcpsCk5sBbVPsB9FAHf8rKNsP3z/rfHtWvAj7dtgpoYFIHmSD2IF9zrclEPl1rLLmT0qa/f0VZTnfnsJsW3CnQ3fnz91MODKGLiIXiMha4F1sL736/tFAKyDTZ/P9nlvxD4tITC3nnuW5lb98586dTjRXNVZkNJz/OJx8m731/tJUnavefHUFfFcvyfFsq+4iz/v5FRHx+xc35O/l2irE1aTzMbYH/e2TUFHmXFsqyuGr2dBtFPQ+ObDXeBPjdq5zrh31UbAR2nau35zvYJaALcqG9l2PLOGrqjgS0I0xrxtjBgLnA/f67hORVOB5YLoxxnsf5nfAQGAUkADcXsu5nzLGpBtj0pOStIMfNkTgtD/AhIdhw8c2WW6ffuBqhvwtOl19nOVtoJcxZgjwMeC3exvS93L5AVuYpXMAGe7VHX+DnU/90+vOtWfVqzZB76TfBr6Ot9s13euT4e6VNAiQ4FSM02VT6+Rolrvn9nxfEUkEEJH22F77H4wx3/gct91YB4D/YG/rqaYo/Wq45EU7bvbMmYdu06nmIgfw7XF3A7b5HmCMyfe8lwGeBkaGqG01y1tjM6Lr20MHOOoMSBxgp7A5kSNSWWmXSE1Og35nB/66jr0gqrV74+gFmfW73Q52JkxCn+DUdNdlU+vU6IAuIkeJ2I+cIjICe2s9X0RaAa8Dzxlj/lvtNameR8H26oNc0V8F1cBz7Fz10t3wzFmQo3PVm5FlQD8R6e15T08B3vI9wPt+9pgIuL+qSNUa6AFmuPuKiIDjr4ftP0LWl41vy7p37d2Ck26x565PO5IGuNNDL90D+3fWv4cOdjqe020uK4W927WHXodApq0tAJYCA0QkR0RmiMi1IuJd7+8iYJWIrMBmw17iSZK7GDgZmOZnetqLIrISWAkkAvc5/HOpUOs+CmZ8ZOfzPjsB1r3vdouUA4wx5cANwAfYQL3QGPOTiNwjIhM9h93omZ76I3AjMM2d1vrIXQmt2tpFThpiyCW2ZvjSxxrXDmPgi3/YXmvaBfV/ffJgd3ro3ilr9clw90o52t6pO1jsXHt2e9I4tIdeq6i6DjDGTK1j/4PAg362vwD4XZPQGHNaoA1UTUjiUTDzY3jxFzZRbsLDMHKa261SjWSMWQQsqrbtTz7f/w6bFxM+tmfYwFKfHrGv6NYwaiZ8/gDs2mD/bzfExsWw7X9wnmdltfpKHgQ/zrflYuMSGtaGhihoQIa7V0oaYGDnGujq0OiLzkEPiFaKU85qm2znqvc9zS6/uvjPOlddhVZlpR3Dbcj4ua9RMyEyBr5pRC99yT+gXRcYOqVhr6/KdA/xymv53h56AwK6t81OJsZ5p8FpD71WGtCV82La2iVYh10Onz8Ib93g7BQgpWpTuMnWSg+khntt2ibB0EtgxQLYn1//12/+BrK/hBN+DVE1zsytnVuZ7gWZ9oNIq7j6vza+N0THOTt1rTDbfrhq29m5czZDGtBVcERGw6RH4eT/s+s+L5hqE22UCjZvQlxje+hgV2ErL7Gro9XXFw9BXCcYeVXDr9++C8S0D/04ekOmrHlFRHiq3DkY0IuyoWP3hg+htBD621HBIwKn/R4mzIbMT+Dx4+HnD91ulWrutmdARJRnTnQjJQ+y09i+e8rOba9PG9Z/AMddZxNFG0rEnRKwDZmy5islDXJXOTfcVpil4+cB0ICugi99Olz9gb0VP/8X8Oo1DbuFqVQgclfaeeTRsc6c7/gbYH8erHwl8Nd8+RC0agejrmn89ZMH2VvuocpFKSmC4vyG99DBJiSWFNhSt04o1DnogdCArkKj+2j45RI45Xb46TV4bJT9A6kJc8ppga6BHqg+Y22AWvpYYP9fd22An96A0TOhdce6j69L8mC7WMy+vMafKxANWZSluqrEOAduu5futivUaQ+9ThrQVehExcCp/88G9o494dUZsGAK7N7qdstUc7F3h+0VOjF+7iViF23J+8lOQ6vLVw/b/+vH/cqZ64c6MS6/nsum+uNkTfdCXWUtUBrQVeilpNn56mfdDxs/h8eOhWXPBGfJRdWyVC2Z6mAPHeDoi+zKbV8/WvtxRVvgx5dgxFU2S94J3t5uqMbRCzIBaXhRHrBz5tulOvMhpGrZ1F6NP1czpwFduSMiEk64Aa7/GroOh3dvsRXmtBa8aoyqDPejnT1vVAyMvsYmd9Y2v3qpJ+Cf8Gvnrt0m0VatC1kPPRM6dGt8DkJKmjM13bWoTMA0oCt3JfSBK9+Cif+yWbFPnABfztY11lXD5GZAxx7QOt75c6fPsIul1FRoZt9Ou476kCl2ipWTQpnp3tgMd6+UNLv0a2NrUBRl26l7wfg3bWY0oCv3icCIK+FX39opQh/fCXNOs1N/lKqP3JXO3273ikuAYZdCxkL/CWrfPA7lpXDizc5fO3mwrRYXiiTSxsxB95WcBhUHG3/XzbtsaqDLzrZgGtBV+GifClNehIufgz3b4amx8PHddqUlpepyYJ8NHsEK6GALzVSUwbI5h28vKbLb0s5veN332iQPstXvvIuUBEtxgc0ob0yGu1dVYlwjb7vrsqkB04Cuws/gSba3PnSqnc/77zGQvdTtVqlwt+MnwDib4V5d4lEwYLwN3mUlh7YvmwMH9sCJtwTnuqFKjPP2pp3ooSf2twV+GjP2bwwUbdbx8wBpQFfhKS4Bzn8Mrnjd3rb7zzh497daPlbVrGoN9CD20MFOYSvOt9nsAAf329vt/c4K3rWTB9rHYCfGOTEH3SuqlQ3qjZm6tn8nlBVrDz1AGtBVeOt7Glz/jb3VuewZLR+rapabYROn2ncN7nV6joHUYbbQTGUl/PCcDfAn3Rq8a8Z2sD9XKHroEuHcFLGUtMYFdM1wrxcN6Cr8tWoD4/4CMz7S8rGqZtsz7Ph5sJOnRGw52Pz1sO5d+OoR6Hki9Dg2uNf1loANpoJM6NDd9q6dkDzYjvuX7m7Y64u0qEx9aEBXTUf3UZ7ysXfAT6/bpLmSQrdbpcJBRZntvQZz/NxX2vm2x/zG9bB3G5wUpLFzX8mDYOfPUFkRvGsUbHRm/NwrxVMPoKFroxdm2ceOPRxpTnOnAV01LVExcOrvYNq79g/pOzdrPXgFu36GigOQOjQ014uMhmN/aRPhUofZoaFgSx5sf8aCTcE5vzG27KsT4+dejc10L8qGNkmNW7GuBdGArpqmHsfauvA/vX4oOUm1XFUlX0PUQwdb3rXbKDjz7tDMkQ52TffifDiw25miMl7tu9jx/4a2WZdNrRcN6KrpGnOTTVBadGvwei2qadieAVGx0Klf6K7ZuqNdk6DP2NBcL3EAIMFLjHNyypqXiL3t3tDEOF02tV4CCugiMldE8kTE730TEZkkIhkiskJElovIiT77rhKR9Z6vq3y2jxSRlSKyQUQeEdEyQKqeIiLhgn+DRMJrs7RcbEuWm2FvSUdGud2S4GkVZ7PPg9VDd3LKmq/kwXYMvb5DYxXlsDtHe+j1EGgPfR4wrpb9nwBDjTHDgKuBOQAikgDcCRwLjAbuFBFvQd4ngFlAP89XbedXyr+OPWDCQ5DzHXzxd7dbo9xgjPNroIer5MHB7aFLpPM94pQ0OLjXFoipjz1bwVRoD70eAgroxpglQEEt+/cZU/Xxqw3g/f5s4CNjTIExphD4CBgnIqlAe2PMUs/rngPOb+gPoVq4YybbBTE+fxA2f+t2a1SoeadFhXL83C3JgyB/A5QfcP7cBZn2A3JktLPnrcp0r+dt9yKdg15fjo2hi8gFIrIWeBfbSwfoCvgWH87xbOvq+b76dn/nneW5jb98586dTjVXNTfn/M3On33tGq0m19J4F/HpHKIMdzclD7K91vwNzp/bqUVZqquqclfPgF6o66DXl2MB3RjzujFmILanfa9ns79xcVPLdn/nfcoYk26MSU9KSnKmsar5iW0PFz5le2vv/Z/brVGhlLsSEEgZ7HZLgi9YNd2NsXPQnR4/B4hpZ4NyQ3roEmHXZlcBcTzL3XN7vq+IJGJ73r4LA3cDtnm2d/OzXamG63EcnHwb/LgAVr3qdmtUqORmQGK/ljFXudNRjV/wxJ99eXY1t2D00MEupVrf4jKF2dC+m/NDAM2YIwFdRI7yZqmLyAigFZAPfACcJSLxnmS4s4APjDHbgb0icpzndVcCbzrRFtXCnfx/dm7wOzdDUZCXmlThIZhroIebqFY2qDvdQw9WhrtXSpotlVufpZB12dR6C3Ta2gJgKTBARHJEZIaIXCsi13oOuQhYJSIrgMeAS4xVgL39vszzdY9nG8B12Gz4DUAm8J5jP5VquSKj7K33ygp4/drglslU7isusMMsLSEhzisYNd2r5qA7WFTGV0oamErYuTbw1xRma0JcPQU0adMYM7WO/Q8CD9awby4w18/25cDRgVxfqXpJ6APj/wpvXg9f/TM0dbaVO7wV4lrClDWv5MG2QuLB/c4NMxRk2lv5HYJUM91bAjZvNXQZVvfxZSWwL1d76PWkleJU8zTsUhh8Piy+H7b+4HZrVLB410BvKbfc4VAJ2Pr0duuSn2kT14JVmCehj63kF2hinHe4THvo9aIBXTVPIjDhYWibYqeyHdzvdotUMOSuhHZdoE2i2y0JnapMdwcDerAy3L0iIu0HkYADui6b2hAa0FXzFZdgS8PmZ8IH/8/t1qhg2J7RssbPwfako2KdG0f3TlkLVoa7V3Ja4AG9atlUDej1oQFdNW+9T4Yxv4Hv58Gad9xujXJSWYldNrUljZ+D7e0m9ncu033vdigrdnaVNX9S0mB/HuwLoEBYUTZExtg7bCpgGtBV83fq7+062W/9GvZsd7s1yil5q23VtJbWQwdna7oHY5U1f7yFfwKpGFeYbcvQRmiIqg/9banmL6oVXDjH9ujeuA4qK91uUZMiIuNEZJ1nZcQ7ajlusogYEUkPScOq1kBvYT10sOPRe7dBSWHjz1Ww0T4Gcwwd6lfTvTBLx88bQAO6ahmS+sO4P8PGxfDtE263pskQkUhsbYnxwGBgqogcUWNVRNoBNwKhWx1newbEtG+Z46xOJsYVZEJkq+CXWG2TaG+hB1IxrkjnoDeEBnTVcoycDgPOgY/vgtxVbremqRgNbDDGbDTGHAReAib5Oe5e4K9APUqBNVLuSnu7vSXelq2auubAbXfvlLWIyMafqy7Jg2FHHe+9kiK7ep720OutBb4TVIslAhP/Ba3j4dWZ9ha8qktNKyZWEZHhQHdjTK1Zh46unFhZYQNDSxw/B9ubbtXOmXH0YE9Z85WSZufP11bBUZdNbTAN6KplaZMI5z9uezYf3el2a5qCWldGFJEI4GHgt3WdyNGVEws22szsljh+DvbDafLAxgf0ysrQTFnzSkmD8tJD4/b+FOoc9IbSgK5anqPOgGOvg++ehJ8/dLs14a6mFRO92mFLOH8mIlnAccBbQU+M2/6jfWypPXQ4VKjF+F15OjB7t9kAG+wpa17eErC13XYv0nXQG0oDumqZzrjLjue9eX1g82JbrmVAPxHpLSKtgCnAW96dxpjdxphEY0wvY0wv4BtgomethuDJXQkR0ZA0MKiXCWvJg6GkAPY34v9vqKaseSUOAImsPTGuMBtiOtihMVUvGtBVyxQdCxfNgdI98NYNjevlNGPGmHLgBuxSyGuAhcaYn0TkHhGZ6FrDcjPsLeeoVq41wXXexLjGVIwL9rKp1UXH2uVfa5u6VpQN8UFaJKaZ04CuWq6UNDjzHvj5fVj+jNutCVvGmEXGmP7GmL7GmPs92/5kjHnLz7Fjg947N8ZT8nVoUC8T9pyYupafacvItu9a97FOSUmr/Za7LpvaYBrQVct27C+h7+nwwe9h5zq3W6MCsTcXine17PFzgDZJENepkT30jRDfO7RT/1IG2174gb1H7jMGijbr+HkDaUBXLZuIzXpv1QZenQHlB9xukapLS1wD3R+RxpeAzc8M3fi5l7dinL9278uD8hLtoTeQBnSl2nWGiY/aQPHaLKgoc7tFqja5ngx3b2BoyZI8U9cakgNSWQGFm0KX4e5VlenuZxxdl01tFA3oSgEMPAfOug9Wv2F76hrUw1fuSnubOLa92y1xX/IgOLgXdufU/7W7c6DiYOh76B2625K9/gJ6oRaVaYwotxugVNg44deAwIe/tz2eyXMhMtrtVqnqWuIa6DWpSoxbAx27135sdaHOcPfyDhX47aFn2ceOmuXeEHX20EVkrojkiYjftEQRuUxEMjxfX4vIUM/2ASKywudrj4jc5Nl3l4hs9dl3jrM/llINdMINcPafYc1b8MrV2lMPN6V77G3ilj5+7pXsmYffkJruoZ6D7islzS6jWn2ooDAb2iRDq7jQt6kZCOSW+zxgXC37NwGnGGOGYBdoeArAGLPOGDPMGDMMGAkUA6/7vO5h735jzKIGtV6pYDj+Vz5BfboG9XDine7UUku+Vtc6Htp1aVhiXMFGiI6DdqnOt6suKYPtAix7th6+vShbx88boc6AboxZAhTUsv9rY4x3Ud5vsKUhqzsdyDTGZDeolUqF2vG/grP/Amvehv9Og/KDbrdIQcteA70myYMaNnUtP9MmxIm/cv1BVrU2erV2F2bp+HkjOJ0UNwN4z8/2KcCCattu8NymnysiNdb4c3SFJqXq4/jrYdwDsPYd21PXoO6+7RkQl2hnJigreZCtoVDbCmb+FGSGPsPdy1vlzrfATEU57N6qPfRGcCygi8ip2IB+e7XtrYCJwH99Nj8B9AWGAduBf9R0XkdXaFKqvo67DsY9aIO69tTdl5thx8/d6FWGq+RBdoGVwqzAX1NRbser3Rg/B4jtAB16HJ4YtycHTIX20BvBkYAuIkOAOcAkY0x+td3jgR+MMTu8G4wxO4wxFcaYSuBpYLQT7VAqKI67Fsb/Fda9q0HdTeUH7VixZrgfriE13Xdvgcqy0Ge4+0pJO7zNumxqozU6oItID+A14ApjzM9+DplKtdvtIuKbhXEBUEthX6XCwLG/hHP+7gnqV2lQd8OudTYI6fj54bwrztUnMa7AxQx3r5TBsOvnQ++lIp2D3lh1zkMXkQXAWCBRRHKAO4FoAGPMv4E/AZ2Ax8XeBis3xqR7XhsHnAn8stpp/yoiwwADZPnZr1T4GX2NfVx0Kyy8Ei5+FqJi3G1TS7I9wz5qQD9cqza29nl9Anr+Rvvo1hg62B56ZbkN6p2Ptj10iYAO/vKqVSDqDOjGmKl17J8JzKxhXzE22FfffkWgDVQqrIy+xo7fvvtbT1B/ToN6qOSutNOs3OxVhqv61nQvyIRWbaFtSvDaVJdknxKwnY+2PfQO3bSYUyNo6Vel6mvUTDj3Ibvs6stX6IIuoZKbYXt1EZFutyT8JA2E/PWBDwXlZ0JCb3eTCzsdBZGtDmW667KpjaYBXamGGDUDJjwM6z+Aly+HslK3W9S8GWN76Hq73b/kwfb2df6GwI4vyHQ3IQ4gMsqzuIwnMU6LyjSaBnSlGir9apgwG9Z/qEE92Aqz4MAezXCvSX0y3SvK3J2y5islzd5yLyuBfTugYy+3W9SkaUBXqjHSp9ugvuEjePkyDerBomug1y6xH0hkYOPoRZvtfG+3e+hgA/re7bBthX2uPfRG0YCuVGOlT4fzHoENH2tQD5bcDBuwvKuLqcNFxdgx6Z1r6z7WzUVZqvP+e67zLOehY+iNogFdKSeMvAom/gs2fAIvXapB3Wm5KyGxP0S3drsl4SvQmu5uLZvqj7em+zpPxXDtoTeKBnSlnDLiShvUMz+Fl6bacUHlDF0DvW7Jg6BgExwsrv24/EyIaQ9tEkPTrtq0Tba1+fPXQ1Ssu9PomgEN6Eo5acQVMOlRyFwMCzSoO2L/Lti7TcfP65I8CDC2ol5tClxcZa06EVsxDqBjj/BoUxOmAV0ppw2/HCY9Bhs/s7XfjXG7RU1brrdCnPbQa+Udj64rMS4/MzzGz728t911/LzRNKArFQzDL4Mz77bFZzZ97nZrmjZdAz0w8b0hMqb2cfTyg3ZhlnAYP/dK8VSM0/HzRtOArlSwjP4ltOsCnz2gvfTG2J4B7btBXILbLQlvkVGQ1B/yasl0L8wCUxlePXTvnQXtoTeaBnSlgiU6Fk66BTYv1V56Y+Su1PHzQNVV0z2cMkw2HsAAABZkSURBVNy9Og+B42+AwZPcbkmTpwFdqWAafoX20hvjYLHNgNbx88AkDYQ9OVC62//+cJqD7hUZBWffr7fcHaABXalg0l564+SttreIdfw8MFWJcTXcdi/IhNiOOnzRTGlAVyrYtJfecNt/tI/aQw9MXTXdCzaGV+9cOUoDulLBpr30hstdaXuUHXu43ZKmoUN3u855TePo+RvDa/xcOUoDulKhoL30hsn1VIjTgiOBiYiw4+g7/QT0slI7ZU176M2WBnSlQkF76fVXUW6X1tTx8/pJHuS/h16YBRhbJU41SxrQlQoV7aXXT/4GKC/VKWv1lTwI9u+EfTsP3x6OU9aUozSgKxUq2kuvn6oKcZoQVy/exLjqt92rpqxpD725qjOgi8hcEckTkVU17L9MRDI8X1+LyFCffVkislJEVojIcp/tCSLykYis9zzGO/PjKBXmtJceuNwfbSnTxP5ut6Rpqamme0EmtE6A1vrntrkKpIc+DxhXy/5NwCnGmCHAvcBT1fafaowZZoxJ99l2B/CJMaYf8InnuVLNXxPspYvIOBFZJyIbROSI96qIXOvzwf1LERnsyIVzV9reZmS0I6drMdqm2KBdfepauC3KohwXVdcBxpglItKrlv1f+zz9BugWwHUnAWM93z8LfAbcHsDrjlBWVkZOTg6lpaUNebmqJjY2lm7duhEdrX9Eg2b4FfDFQ7aX3vuUsM7gFpFI4DHgTCAHWCYibxljfKPFfGPMvz3HTwQeovZOQN2MsTXcB01o1GlaJBFPCdhqxWUKNkKvk9xpkwqJOgN6Pc0A3vN5boAPRcQATxpjvL33FGPMdgBjzHYRSa7phCIyC5gF0KPHkXNRc3JyaNeuHb169ULC+A9jU2CMIT8/n5ycHHr37u12c5ovby990a22l95nrNstqs1oYIMxZiOAiLyE/UBeFdCNMXt8jm+Dfd83zp5tUFKgGe4NlTwIMv5rPxiJ2BK6e7ZqD72ZcywpTkROxQZ03572GGPMCGA88CsRObm+5zXGPGWMSTfGpCclJR2xv7S0lE6dOmkwd4CI0KlTJ73bEQpNZyy9K7DF53mOZ9thRORXIpIJ/BW40d+JRGSWiCwXkeU7d+70d8ghbVPg2i91wY6GShoIB3bbD0YAhZvso05Za9YcCegiMgSYA0wyxuR7txtjtnke84DXsZ/2AXaISKrntalAXiOv35iXKx/6uwyRpjOW7u8/xBGfQIwxjxlj+mI/0P/B34nq+nB+mMgom93etsabd6o21RPjwnFRFuW4Rgd0EekBvAZcYYz52Wd7GxFp5/0eOAvwZsq/BVzl+f4q4M3GtkOpJqdp9NJzgO4+z7sB22o5/iXg/KC2SNWtek13nYPeIgQybW0BsBQYICI5IjLDk9V6reeQPwGdgMerTU9LAb4UkR+B74B3jTHve/Y9AJwpIuuxyTYPOPgzhbW2bdsCsG3bNiZPnuz3mLFjx7J8+XK/+7xmz55NcXFx1fNzzjmHoqIi5xqqgq9p9NKXAf1EpLeItAKmYD+QVxGRfj5PzwXWh7B9yp+4BGjb+fAeepskiG3vbrtUUAWS5T61jv0zgZl+tm8Ehh75CvDclj89wDY2S126dOGVV15p8Otnz57N5ZdfTlxcHACLFi1yqmkqlMI8490YUy4iNwAfAJHAXGPMTyJyD7DcGPMWcIOInAGUAYUcuvum3JQ8yKeHrouytAROZ7m76u63f2L1tj11H1gPg7u0587z0mrcf/vtt9OzZ0+uv/56AO666y5EhCVLllBYWEhZWRn33XcfkyYdntyTlZXFhAkTWLVqFSUlJUyfPp3Vq1czaNAg/n979x5WdZ0ncPz94SL3uAoiKJcsEQ1BSZgwRystc7Kb21rarJbjjNuk9bQ73Z5ma59pn3YetzZ3Jn2ysWl2tHI1bbcyLy3e1iAhjRAsUkDwgshNEbwA3/3jHBGQm3LiXPi8/jnn/M75/fic3+F7Puf7/X0vjY2Nra9btGgRe/fupbGxkVmzZvHKK6+wbNkyjh07xpQpUwgLCyMzM5PY2FhycnIICwvj9ddfZ9WqVQAsWLCAp556ipKSEqZPn87EiRPZs2cPUVFRfPzxx/j4+Nj0fKmr5AQ93o0xnwGfddj22zb3l/R7UKpn4YmQswpaWiw19BEDug41IOjUr300e/ZsPvzww9bHa9euZf78+WzYsIGvv/6azMxMnnnmGUw310iXL1+Or68veXl5vPjii+Tm5rY+9+qrr5KTk0NeXh47duwgLy+PxYsXM3ToUDIzM8nMzGx3rNzcXN59912ys7PJyspi5cqV7Nu3D4CioiKeeOIJDhw4QFBQEOvXr7fx2VDXxDmupStnE54ATY1w8gDUn9Ae7gOAS9XQu6tJ/1hSUlI4efIkx44do7KykuDgYCIjI3n66afZuXMnbm5uHD16lIqKCoYMGdLpMXbu3MnixZaRPklJSSQlXR57u3btWt5++22ampo4fvw4BQUF7Z7vaPfu3dx///34+fkB8MADD7Br1y5mzpxJXFwcycnJAIwfP56SkhIbnQXVJ05QS1c/rnMXm9l3pJasw1WIwPxb4gj07ePkTpd6uh/81HKrPdxdnksldHuZNWsW69at48SJE8yePZvVq1dTWVlJbm4unp6exMbG9ji2u7PhYsXFxSxdupS9e/cSHBzMvHnzejxOdy0BXl5erffd3d3bNe0rOxv3c4e+lq5sq/FCM/uO1JB1uIqs4mr2H6nlQnMLbmIZE/jnPSUsvu0G5qbHMMjjGhtSB4+03B78xHKr19Bdnja528Ds2bP54IMPWLduHbNmzaKuro7w8HA8PT3JzMyktLS02/0nTZrE6tWrAcjPzycvLw+A06dP4+fnR2BgIBUVFWzadHkSvoCAAM6cOdPpsTZu3EhDQwNnz55lw4YN3HqrTvfo8Dy8nKHHu7pGDRea2F10iqWbv+NvVuwh6ZXNPPJONn/I/IFzF5uZlxHLn/4ulX2/ncanT97KmKGB/PMnBUx7Ywef55/o9od6l7wCIGj45VXrtMnd5WkN3QZGjx7NmTNniIqKIjIykjlz5nDPPfeQmppKcnIyCQkJ3e6/aNEi5s+fT1JSEsnJyUyYYJl/Z+zYsaSkpDB69Gji4+PJyMho3WfhwoVMnz6dyMjIdtfRx40bx7x581qPsWDBAlJSUrR53RloLd1lnD3fRG6ppQaeXVzNN2W1NLUY3N2EMVGBPDYxjvS4UFJjgwnwbt+0HujjyX8+PoHt31XyL58V8qu/5jIhNoQXZ4xi7LCgqwskPBFqj1iGsHn52/AdKkck1/TLz05SU1NNx/HZhYWFjBo1yk4RuSY9p3b01UrLtfSff9yna+kiktthhUOH0llZdmb155vIKakm63A12cVVfFte15rAk6IDSYsLJT0+hNTYEPy9el+Pampu4cOcMt7Y+j2n6i9wb/JQfnNXAlFBvRydsu1l2P0GxGTAfB3a6oyupixrDV0pR6K1dId29nwTR2sbOVrTSHlNAyVVDeSU1pB/tI7mFoOHmzB2WBALJ8WTHh/K+Jhg/K4igXfk4e7GnLQYZo4dyoodh3hnVzGb8k/w+MQ4/n7y9VfU7q8w2PrDPEQXWxoINKEr5UguXUvXHu92UX++qTVZl7e5PVrbSHlNI9VnL7R7/SAPN8ZGB7Lop9eTHh/KuJggfAfZ/ms1wNuTf7wzgUfSYli6+TuWbz/E2r1lPDX1Rh6+eRge7l10h7o0Bax2iBsQNKEr5Wi0lv6jOX3uojVht0nWNY2U11ru1zZcbPd6Lw83ooJ9iA72ZUxUINHBPkQFWR4PC/YhzN8LN7f++3yignx442+TmZ8Ry+8+LeSljfm8t6eEF+5OYMrI8CtHy0SMholPw02dTzOtXIsmdKUcjdbSbaasuoHs4mpr57QqyqrbD9X08XS3JOlgH5KHBREd7GtN2JakHeY/yCFXIEyKDuLDhelsKajgtU0HeezPOWSMCOXFuxNJHNpmvnY3d7jjZXuFqfqZJnSlHJHW0q+aMYay6kayiqssCfxwNUdrLQk82NeTtLhQ5qTFMDzkctIO8XPMhN0bIsKdo4cwZWQ4q7NLefOLImb8xy5mjYvmH+4cScR13vYOUfUzTehKOSKtpffIGENpVQPZxVWW3uWHqzhWZ5l4KcRvEGlxIa2d024I9+/XpvH+NMjDjfkZcTyQEs0fMot4b08pn+Qd5xeT4vnlpPg+dcpTzkU/6T6qra1lzZo1rYuz9Nbdd9/NmjVrCAq6ynGlauDQWno7xhiKT5293IR+uJoTpy0JPMx/EGlxoSyKDyHNmsCdteZ9rQJ9PXlxRiKPpsfyr5sPsuyLIj746ghPT72Rm6IC7R1et9xEGBHuf+2z4jmh0+cuUnqqgZuibffZaELvo9raWt56660rEnpzczPu7u5d7qfLnaoeDfBaujGGQ5Vn29XAT545D8DgAC/S4kJIj7eM775+8MBL4F0ZHurLHx8Zx2MZ1fzu00Ke/+hbe4fUKwFeHkxOCGdaYgSTRw7ueUieEzpe18i2ggq2FFSQdbiKUD8vvnz+Npv977pWQt/03OVpDm1lyE0w/bUun37uuec4dOgQycnJeHp64u/vT2RkJPv376egoID77ruPsrIyzp07x5IlS1i4cCFA63Kn9fX1uqyp6toAraWXVTdw/1t7OFVvSeDhAV6kx4eSFm9J4vFhfprAezA+JoSPFt1CdnE1pxsv9ryDHZ1rauH/ik6xrbCC//nmGJ7uwk+uD2NqYgRTR0UwJNA5+wMYY/iu4gxbD1SwtbCCvPI6AOLD/HhsYhzTEiNs+vdcK6HbwWuvvUZ+fj779+9n+/btzJgxg/z8fOLiLBM5rFq1ipCQEBobG7n55pt58MEHCQ0NbXeMoqIi3n//fVauXMlDDz3E+vXrmTt3rj3ejnI0A7SWPjTIh9sSBpMyPJj0+FBiQ301gV8DESE9PrTnFzqAmWOH0txi2Hekhq3WWuxLG/N5aWM+Y6MDmZoYwbTRQxz+ckpTcwu5pTVsKahga0EFR6obAEgZHsSzdyUwNTGCEeE/zjS8rpXQu6lJ95cJEya0JnOAZcuWsWHDBgDKysooKiq6IqHrsqaqWwOwlu7uJvx+1lh7h6H6mbubkBprmSL3uekJHKqsZ/MBS2JcuuV7lm75nphQX6YlRjA1cQjjY4Jxd4DOjo0XmtlZVMnWggq+KKygpuEig9zdyBgRyq9+ej13jAonvB9GHbhWQncAl9YhB9i+fTvbtm3jyy+/xNfXl8mTJ3e6/Kkua6q6NUBr6WpgExFGhAcwIjyAJ6aMoOL0ObYVWpL7e3tKWbmrmBC/QdyeEM7UxAhuvWEwPoO67rdka1X15/mi8CRbCirYVVTJ+aYWrvP24PZREUxNjGDSjYOvat5+W9CE3kddLWMKUFdXR3BwML6+vhw8eJCsrKx+jk65jAFYS1eqrYjrvJmTFsOctBjqzzex47tKthSc4PMDJ/iv3HK8Pd249YbBTE2M4PaEcEL9vXo+6FUqOXWWLQUn2FpQQW5pDS3GMnvfwxOGMy0xgpvjQvDsahreftBjQheRVcDPgJPGmDGdPD8HeNb6sB5YZIz5RkSGAX8BhgAtwNvGmDet+7wM/AKotO73gjHGKbt9h4aGkpGRwZgxY/Dx8SEi4nInh7vuuosVK1aQlJTEyJEjSU9Pt2OkyqlpLV2pVv5eHsxIimRGUiQXm1v4qriaLQcsiXZrQQVuArFhfrjb8Idv48VmymssraeJkdfx5G03MG10BImR1znMNf0el08VkUlYEvVfukjotwCFxpgaEZkOvGyMSRORSCDSGPO1iAQAucB9xpgCa0KvN8YsvZpgdfnU/qHn1EE1nYcP5kDGEoi7tduX6vKpaiAyxnDg2Gm2FFTww8nOW06vlZsI42OCuWNUBMNCfG167O7YdPlUY8xOEYnt5vk9bR5mAdHW7ceB49b7Z0SkEIgCCnoTmFKqAw8vmLvO3lEo5bBEhDFRgYxx8Il0fiy2bux/HNjUcaP1B0EKkN1m869FJE9EVolIcFcHFJGFIpIjIjmVlZVdvUwppZQa0GyW0EVkCpaE/myH7f7AeuApY8xp6+blwPVAMpZa/L91dVxjzNvGmFRjTOrgwYO7ek3f34AC9FwqpZSzsklCF5Ek4B3gXmNMVZvtnliS+WpjzEeXthtjKowxzcaYFmAlMOFa/7a3tzdVVVWaiGzAGENVVRXe3s45K5NSSg1kfR62JiLDgY+AR40x37fZLsCfsHSYe73DPpHWa+wA9wP51/r3o6OjKS8vR5vjbcPb25vo6Gh7h6GUUuoq9WbY2vvAZCBMRMqBfwI8AYwxK4DfAqHAW9au+03WHnkZwKPAtyKy33q4S8PTfi8iyYABSoBfXusb8PT0bDczm1JKKTUQ9aaX+8M9PL8AWNDJ9t1Ap4PzjDGP9jZApZRSSvVs4Cw+q5RSSrkwTehKKaWUC+hxpjhHIiKVQGkPLwsDTvVDOH2hMdqGxti1GGNM5+M8HUAvyzLoZ2wrGqNt2CPGXpdlp0rovSEiOY485SVojLaiMbo+Zzh/GqNtaIx9p03uSimllAvQhK6UUkq5AFdM6G/bO4Be0BhtQ2N0fc5w/jRG29AY+8jlrqErpZRSA5Er1tCVUkqpAUcTulJKKeUCXCqhi8hdIvKdiPwgIs/ZO56ORGSYiGSKSKGIHBCRJfaOqTMi4i4i+0TkE3vH0hURCRKRdSJy0Ho+f2LvmDoSkaetn3O+iLwvIrqMXS9pWbYdRy/PWpZtx2USuoi4A38EpgOJwMMikmjfqK7QBDxjjBkFpANPOGCMAEuAQnsH0YM3gc+NMQnAWBwsXhGJAhYDqcaYMYA7MNu+UTkHLcs25+jlWcuyjbhMQseypvoPxpjDxpgLwAfAvXaOqR1jzHFjzNfW+2ew/ONG2Teq9kQkGpiBZX17hyQi1wGTsCzPizHmgjGm1r5RdcoD8BERD8AXOGbneJyFlmUbcfTyrGXZtlwpoUcBZW0el+OABewSEYkFUoBs+0ZyhX8HfgO02DuQbsQDlcC71qbEd0TEz95BtWWMOQosBY4Ax4E6Y8wW+0blNLQs246jl2ctyzbkSgm9s6VaHXJMnoj4A+uBp4wxp+0dzyUi8jPgpDEm196x9MADGAcsN8akAGcBh7rOKiLBWGqVccBQwE9E5to3KqehZdkGnKQ8a1m2IVdK6OXAsDaPo3HAZhER8cTyBbDaGPORvePpIAOYKSIlWJo5bxORv9o3pE6VA+XGmEs1onVYvhQcyR1AsTGm0hhzEfgIuMXOMTkLLcu24QzlWcuyDblSQt8L3CAicSIyCEunhf+2c0ztiIhguVZUaIx53d7xdGSMed4YE22MicVy/v7XGONwv0SNMSeAMhEZad10O1Bgx5A6cwRIFxFf6+d+Ow7W2ceBaVm2AWcoz1qWbcvD3gHYijGmSUR+DWzG0gtxlTHmgJ3D6igDeBT4VkT2W7e9YIz5zI4xOasngdXWL/zDwHw7x9OOMSZbRNYBX2PpEb0PB5820lFoWR5wtCzbiE79qpRSSrkAV2pyV0oppQYsTehKKaWUC9CErpRSSrkATehKKaWUC9CErpRSSrkATehKKaWUC9CErpRSSrmA/wdxYyJV1msruAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "train_loader, test_loader, val_loader,_ = loader()(subject= \"ALL\",\n",
    "                                             batch_size= 30,\n",
    "                                             num_validation =38,use_cuda=True)\n",
    "model = VAE_CNNShallow().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9,0.999), eps=1e-08, weight_decay=0.005)\n",
    "main_train(epoches = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
